{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunrui/anaconda3/envs/cell-tracking-challenge/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /data/sunrui/celldata/r03c06f04ch1/01_RES_inference/pytorch_geometric_data.pt\n",
      "Load /data/sunrui/celldata/r03c06f04ch1/01_RES_inference/all_data_df.csv\n",
      "Load /data/sunrui/celldata/r03c06f04ch1/01_RES_inference/raw_output.pt\n",
      "tensor([[    0,     1,     2,  ..., 16137, 16139, 16146],\n",
      "        [   53,    55,    54,  ..., 16167, 16154, 16171]])\n",
      "currID_not_in_predID [113]\n",
      "currID_not_in_predID [41, 113]\n",
      "currID_not_in_predID [41, 113]\n",
      "currID_not_in_predID [41, 113]\n",
      "currID_not_in_predID [41, 113]\n",
      "currID_not_in_predID [41, 113]\n",
      "currID_not_in_predID [41, 43, 113]\n",
      "currID_not_in_predID [43, 113]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 546\u001b[0m\n\u001b[1;32m    538\u001b[0m pp \u001b[39m=\u001b[39m Postprocess(is_3d\u001b[39m=\u001b[39mis_3d,\n\u001b[1;32m    539\u001b[0m                     type_masks\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtif\u001b[39m\u001b[39m'\u001b[39m, merge_operation\u001b[39m=\u001b[39mmerge_operation,\n\u001b[1;32m    540\u001b[0m                     decision_threshold\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[1;32m    541\u001b[0m                     path_inference_output\u001b[39m=\u001b[39mpath_inference_output, center_coord\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    542\u001b[0m                     directed\u001b[39m=\u001b[39mdirected,\n\u001b[1;32m    543\u001b[0m                     path_seg_result\u001b[39m=\u001b[39mpath_Seg_result)\n\u001b[1;32m    545\u001b[0m all_frames_traject, trajectory_same_label, df_trajectory, str_track \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39mcreate_trajectory()\n\u001b[0;32m--> 546\u001b[0m pp\u001b[39m.\u001b[39;49mfill_mask_labels(debug\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn[1], line 504\u001b[0m, in \u001b[0;36mPostprocess.fill_mask_labels\u001b[0;34m(self, debug)\u001b[0m\n\u001b[1;32m    502\u001b[0m mask_val \u001b[39m=\u001b[39m (pred_copy \u001b[39m==\u001b[39m val)\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    503\u001b[0m mask_curr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlogical_and(mask_val, mask_where)\n\u001b[0;32m--> 504\u001b[0m pred_copy[mask_curr] \u001b[39m=\u001b[39m true_id\n\u001b[1;32m    505\u001b[0m \u001b[39m# if not np.any(mask_curr):\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[39m#     print('empty1')\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[39m# if idx == 4 :\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[39m#         plt.imshow(mask_curr)\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[39m#         # plt.show()\u001b[39;00m\n\u001b[1;32m    519\u001b[0m mask_where \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlogical_and(np\u001b[39m.\u001b[39mlogical_not(mask_val), mask_where)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Postprocess(object):\n",
    "    def __init__(self,\n",
    "                 is_3d,\n",
    "                 type_masks,\n",
    "                 merge_operation,\n",
    "                 decision_threshold,\n",
    "                 path_inference_output,\n",
    "                 center_coord,\n",
    "                 path_seg_result,\n",
    "                 directed=True\n",
    "                 ):\n",
    "\n",
    "        file1 = os.path.join(path_inference_output, 'pytorch_geometric_data.pt')\n",
    "        file2 = os.path.join(path_inference_output, 'all_data_df.csv')\n",
    "        file3 = os.path.join(path_inference_output, 'raw_output.pt')\n",
    "\n",
    "        self.dir_result = dir_results = path_seg_result\n",
    "        self.results = []\n",
    "        if os.path.exists(dir_results):\n",
    "            self.results = [os.path.join(dir_results, fname) for fname in sorted(os.listdir(dir_results))\n",
    "                            if type_masks in fname]\n",
    "\n",
    "        self.is_3d = is_3d\n",
    "        self.center_coord = center_coord\n",
    "        self.merge_operation = merge_operation\n",
    "        self.decision_threshold = decision_threshold\n",
    "        self.directed = directed\n",
    "        self.path_inference_output = path_inference_output\n",
    "        self.cols = [\"child_id\", \"parent_id\", \"start_frame\"]\n",
    "\n",
    "        data = self._load_file(file1)\n",
    "        self.edge_index = data.edge_index\n",
    "\n",
    "        self.df_preds = self._load_file(file2)\n",
    "        self.output_pred = self._load_file(file3)\n",
    "        self.find_connected_edges()\n",
    "\n",
    "    def _load_file(self, file_path):\n",
    "        print(f\"Load {file_path}\")\n",
    "        file_type = file_path.split('.')[-1]\n",
    "        if file_type == 'csv':\n",
    "            file = pd.read_csv(file_path, index_col=0)\n",
    "        if file_type == 'pt':\n",
    "            file = torch.load(file_path)\n",
    "        return file\n",
    "\n",
    "    def save_csv(self, df_file, file_name):\n",
    "        full_name = os.path.join(self.path_inference_output, f\"postprocess_data\")\n",
    "        os.makedirs(full_name, exist_ok=True)\n",
    "        full_name = os.path.join(full_name, file_name)\n",
    "        df_file.to_csv(full_name)\n",
    "\n",
    "    def save_txt(self, str_txt, output_folder, file_name):\n",
    "        full_name = os.path.join(output_folder, file_name)\n",
    "        with open(full_name, \"w\") as text_file:\n",
    "            text_file.write(str_txt)\n",
    "\n",
    "    def insert_in_specific_col(self, all_frames_traject, frame_ind, curr_node, next_node):\n",
    "        if curr_node in all_frames_traject[frame_ind, :]:\n",
    "            flag = 0\n",
    "            ind_place = np.argwhere(all_frames_traject[frame_ind, :] == curr_node)\n",
    "            if frame_ind + 1 < all_frames_traject.shape[0]:\n",
    "                all_frames_traject[frame_ind + 1, ind_place] = next_node\n",
    "        else:\n",
    "            flag = 1\n",
    "            ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -2)\n",
    "            while ind_place.size == 0:\n",
    "                new_col = -2 * np.ones((all_frames_traject.shape[0], 1), dtype=all_frames_traject.dtype)\n",
    "                all_frames_traject = np.append(all_frames_traject, new_col, axis=1)\n",
    "                ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -2)\n",
    "            ind_place = ind_place.min()\n",
    "            all_frames_traject[frame_ind, ind_place] = curr_node\n",
    "            if frame_ind + 1 < all_frames_traject.shape[0]:\n",
    "                all_frames_traject[frame_ind + 1, ind_place] = next_node\n",
    "\n",
    "        return flag, all_frames_traject\n",
    "\n",
    "    def fill_first_frame(self, cell_starts):\n",
    "        cols = [\"child_id\", \"parent_id\", \"start_frame\"]\n",
    "        df_parent = pd.DataFrame(index=range(len(list(cell_starts))), columns=cols)\n",
    "        df_parent.loc[:, [\"start_frame\", \"parent_id\"]] = 0\n",
    "        df_parent.loc[:, \"child_id\"] = cell_starts\n",
    "        return df_parent\n",
    "\n",
    "    def find_parent_cell(self, frame_ind, all_frames_traject, df, num_starts, cell_starts):\n",
    "        ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -1)#轨迹结束位置\n",
    "        finish_node_ids = all_frames_traject[frame_ind - 1, ind_place].squeeze(axis=1)#轨迹结束的位置与结束的nodes\n",
    "        # print(f\"frame_ind: {frame_ind}, cell_starts: {cell_starts}, cell_ends: {finish_node_ids}\")\n",
    "\n",
    "        df_parent = pd.DataFrame(index=range(len(cell_starts)), columns=self.cols)\n",
    "        df_parent.loc[:, \"start_frame\"] = frame_ind#存在新细胞轨迹，保存开始帧数\n",
    "\n",
    "        if finish_node_ids.shape[0] != 0:#存在轨迹结束\n",
    "            if self.is_3d:\n",
    "                finish_cell = df.loc[finish_node_ids, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "            else:\n",
    "                finish_cell = df.loc[finish_node_ids, [\"centroid_row\", \"centroid_col\"]].values#保存结尾id中心位置\n",
    "            for ind, cell in enumerate(cell_starts):\n",
    "                if self.is_3d:\n",
    "                    curr_cell = df.loc[cell, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "                else:\n",
    "                    curr_cell = df.loc[cell, [\"centroid_row\", \"centroid_col\"]].values#保存新开始的细胞ID\n",
    "\n",
    "                distance = ((finish_cell - curr_cell) ** 2).sum(axis=-1)\n",
    "                nearest_cell = np.argmin(distance, axis=-1)\n",
    "                parent_cell = int(finish_node_ids[nearest_cell])#最近的结束细胞为亲代\n",
    "                df_parent.loc[ind, \"child_id\"] = cell\n",
    "                df_parent.loc[ind, \"parent_id\"] = parent_cell\n",
    "        else:\n",
    "            df_parent.loc[:, \"child_id\"] = cell_starts\n",
    "            df_parent.loc[:, \"parent_id\"] = 0\n",
    "\n",
    "        return df_parent\n",
    "\n",
    "    def clean_repetition(self, df):\n",
    "        all_childs = df.child_id.values\n",
    "        unique_vals, count_vals = np.unique(all_childs, return_counts=True)\n",
    "        prob_vals = unique_vals[count_vals > 1]\n",
    "        for prob_val in prob_vals:\n",
    "            masking = df.child_id.values == prob_val\n",
    "            all_apearence = df.loc[masking, :]\n",
    "            start_frame = all_apearence.start_frame.min()\n",
    "            end_frame = all_apearence.end_frame.max()\n",
    "            df.loc[all_apearence.index[0], [\"start_frame\", \"end_frame\"]] = start_frame, end_frame\n",
    "            df = df.drop(all_apearence.index[1:])\n",
    "\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "    def set_all_info(self, df_parents_all, all_frames_traject):\n",
    "\n",
    "        iterate_childs = df_parents_all.child_id.values\n",
    "        frames_traject_same_label = all_frames_traject.copy()\n",
    "        for ind, child_ind in enumerate(iterate_childs):\n",
    "            # find the place where we store the child_ind in the trajectory matrix\n",
    "            # validate that only one place exists\n",
    "            coordinates_child = np.argwhere(all_frames_traject == child_ind)\n",
    "            n_places = coordinates_child.shape[0]\n",
    "\n",
    "            assert n_places == 1, f\"Problem! find {n_places} places which the current child appears\"\n",
    "\n",
    "            coordinates_child = coordinates_child.squeeze()\n",
    "            row, col = coordinates_child\n",
    "            s_frame = df_parents_all.loc[ind, \"start_frame\"]\n",
    "            assert row == s_frame, f\"Problem! start frame {s_frame} is not equal to row {row}\"\n",
    "\n",
    "            # take the specific col from 'row' down\n",
    "            curr_col = all_frames_traject[row:, col]\n",
    "            last_ind = np.argwhere(curr_col == -1)\n",
    "            if last_ind.size != 0:\n",
    "                last_ind = last_ind[0].squeeze()\n",
    "                curr_col = curr_col[:last_ind]\n",
    "            e_frame = row + curr_col.shape[0] - 1\n",
    "\n",
    "            df_parents_all.loc[ind, \"end_frame\"] = int(e_frame)\n",
    "            # curr_id = curr_col[-1]#以最后一位结尾作为curr_id change\n",
    "            curr_id = curr_col[0]\n",
    "            # print(curr_id)\n",
    "            df_parents_all.loc[ind, \"child_id\"] = curr_id\n",
    "            frames_traject_same_label[row:e_frame + 1, col] = curr_id#以最后一位的node构建图像\n",
    "\n",
    "        assert not(df_parents_all.isnull().values.any()), \"Problem! dataframe contains NaN values\"\n",
    "        df_parents_all = self.clean_repetition(df_parents_all.astype(int))\n",
    "        return df_parents_all.astype(int), frames_traject_same_label#如果结尾在同一个mask上，则导致两条细胞轨迹为同一mask值\n",
    "\n",
    "    def df2str(self, df_track):\n",
    "        \"\"\"\n",
    "        L B E P where\n",
    "        L - a unique label of the track (label of markers, 16-bit positive value)\n",
    "        B - a zero-based temporal index of the frame in which the track begins\n",
    "        E - a zero-based temporal index of the frame in which the track ends\n",
    "        P - label of the parent track (0 is used when no parent is defined)\n",
    "        \"\"\"\n",
    "        str_track = ''\n",
    "        for i in df_track.index:\n",
    "            L = df_track.loc[i, \"child_id\"]\n",
    "            B = df_track.loc[i, \"start_frame\"]\n",
    "            E = df_track.loc[i, \"end_frame\"]\n",
    "            P = df_track.loc[i, \"parent_id\"]\n",
    "            str_track += f\"{L} {B} {E} {P}\\n\"\n",
    "\n",
    "        return str_track\n",
    "\n",
    "    def merge_edges(self):\n",
    "        in_output_pred, out_output_pred = self.match_edges()\n",
    "        if self.merge_operation == 'OR' or self.merge_operation == 'AND':\n",
    "            in_outputs_soft = torch.sigmoid(in_output_pred)\n",
    "            in_outputs_hard = (in_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            out_outputs_soft = torch.sigmoid(out_output_pred)\n",
    "            out_outputs_hard = (out_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            final_outputs_hard = np.bitwise_or(in_outputs_hard,out_outputs_hard) if self.merge_operation == 'OR'\\\n",
    "                else np.bitwise_and(in_outputs_hard,out_outputs_hard)\n",
    "\n",
    "        if self.merge_operation == 'AVG':\n",
    "            avg_outputs_soft = torch.sigmoid(in_output_pred) + torch.sigmoid(out_output_pred)\n",
    "            avg_outputs_soft = avg_outputs_soft / 2.0\n",
    "            final_outputs_hard = (avg_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "        self.outputs_hard = final_outputs_hard\n",
    "        return final_outputs_hard\n",
    "\n",
    "    def megre_match_edges(self, edge_index, output_pred):\n",
    "\n",
    "        assert torch.all(edge_index[:, ::2] == edge_index[[1, 0], 1::2]), \\\n",
    "            \"The results don't match!\"\n",
    "        edge_index = edge_index[:, ::2]\n",
    "        in_output_pred = output_pred[::2]\n",
    "        out_output_pred = output_pred[1::2]\n",
    "\n",
    "        if self.merge_operation == 'OR' or self.merge_operation == 'AND':\n",
    "            in_outputs_soft = torch.sigmoid(in_output_pred)\n",
    "            in_outputs_hard = (in_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            out_outputs_soft = torch.sigmoid(out_output_pred)\n",
    "            out_outputs_hard = (out_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            final_outputs_hard = np.bitwise_or(in_outputs_hard, out_outputs_hard) if self.merge_operation == 'OR' \\\n",
    "                else np.bitwise_and(in_outputs_hard, out_outputs_hard)\n",
    "\n",
    "        elif self.merge_operation == 'AVG':\n",
    "            avg_outputs_soft = torch.sigmoid(in_output_pred) + torch.sigmoid(out_output_pred)\n",
    "            avg_outputs_soft = avg_outputs_soft / 2.0\n",
    "            final_outputs_hard = (avg_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "        return final_outputs_hard, edge_index\n",
    "\n",
    "    def find_connected_edges(self):\n",
    "        edge_index, df, outputs = self.edge_index, self.df_preds, self.output_pred\n",
    "\n",
    "        if not self.directed:\n",
    "            final_outputs_hard, edge_index = self.megre_match_edges(edge_index.detach().clone(), outputs.detach().clone())\n",
    "            self.outputs_hard = final_outputs_hard\n",
    "            self.edge_index = edge_index\n",
    "        else:\n",
    "            outputs_soft = torch.sigmoid(outputs)\n",
    "            self.outputs_hard = (outputs_soft > self.decision_threshold).int()\n",
    "    \n",
    "    def test(self):\n",
    "        edge_index, df, outputs_hard = self.edge_index, self.df_preds, self.outputs_hard\n",
    "        connected_indices = edge_index[:, outputs_hard.bool()]\n",
    "        return edge_index, connected_indices\n",
    "\n",
    "    def create_trajectory(self):\n",
    "        edge_index, df, outputs_hard = self.edge_index, self.df_preds, self.outputs_hard\n",
    "        self.flag_id0_terminate = False\n",
    "        # extract values from arguments\n",
    "        connected_indices = edge_index[:, outputs_hard.bool()]\n",
    "        print(connected_indices)#change\n",
    "\n",
    "        # find number of frames for iterations\n",
    "        frame_nums = np.unique(df.frame_num)\n",
    "        # find number of cells in each frame and build matrix [num_frames, max_cells]\n",
    "        max_elements = [df.frame_num.isin([i]).sum() for i in frame_nums]\n",
    "        all_frames_traject = np.zeros((frame_nums.shape[0], max(max_elements)))\n",
    "        #创建轨迹图，横轴是帧数，纵轴是某一帧出现的最多细胞数 \n",
    "\n",
    "        # intialize the matrix with -2 meaning empty cell, -1 means end of trajectory,\n",
    "        # other value means the number of node in the graph\n",
    "        all_frames_traject[:, :] = -2\n",
    "        all_trajectory_dict = {}\n",
    "        str_track = ''\n",
    "        df_parents = []\n",
    "        for frame_ind in frame_nums:\n",
    "            mask_frame_ind = df.frame_num.isin([frame_ind])  # find the places containing frame_ind\n",
    "\n",
    "            # filter the places with the specific frame_ind and take the corresponding indices\n",
    "            nodes = df.loc[mask_frame_ind, :]\n",
    "            nodes_indices = nodes.index.values\n",
    "            #nodes_indices为当前帧的mask的唯一标识值\n",
    "\n",
    "            next_frame_indices = np.array([])\n",
    "\n",
    "            if frame_ind == 0:  # for the first frame, we should fill the first row with node indices\n",
    "                all_frames_traject[frame_ind, :nodes_indices.shape[0]] = nodes_indices\n",
    "                df_parents.append(self.fill_first_frame(nodes_indices))\n",
    "\n",
    "            num_starts = 0\n",
    "            cell_starts = []\n",
    "            for i in nodes_indices:\n",
    "                if i in connected_indices[0, :]:\n",
    "                    ind_place = np.argwhere(connected_indices[0, :] == i)\n",
    "\n",
    "                    if ind_place.shape[-1] > 1:\n",
    "                        next_frame_ind = connected_indices[1, ind_place].numpy().squeeze()\n",
    "                        if self.is_3d:\n",
    "                            next_frame = df.loc[next_frame_ind, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "                            curr_node = df.loc[i, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "                        else:\n",
    "                            next_frame = df.loc[next_frame_ind, [\"centroid_row\", \"centroid_col\"]].values\n",
    "                            curr_node = df.loc[i, [\"centroid_row\", \"centroid_col\"]].values\n",
    "\n",
    "                        distance = ((next_frame - curr_node) ** 2).sum(axis=-1)\n",
    "                        nearest_cell = np.argmin(distance, axis=-1)\n",
    "                        # add to the array\n",
    "                        next_node_ind = next_frame_ind[nearest_cell]\n",
    "\n",
    "                    elif ind_place.shape[-1] == 1:  # one node in the next frame is connected to current node\n",
    "                        next_node_ind = connected_indices[1, ind_place[0]]\n",
    "                    else:  # no node in the next frame is connected to current node -\n",
    "                        # in this case we end the trajectory\n",
    "                        next_node_ind = -1\n",
    "\n",
    "                else:\n",
    "                    # we dont find the current node in the edge indices matrix - meaning we dont have a connection\n",
    "                    # for the node - in this case we end the trajectory and the cell\n",
    "                    if i == 0:\n",
    "                        self.flag_id0_terminate = True\n",
    "                    next_node_ind = -1\n",
    "\n",
    "                next_frame_indices = np.append(next_frame_indices, next_node_ind)#保存连接结果\n",
    "                # count the number of starting trajectories\n",
    "                start, all_frames_traject = self.insert_in_specific_col(all_frames_traject, frame_ind, i, next_node_ind)\n",
    "                num_starts += start\n",
    "\n",
    "                if start == 1:  # append the id of the cell to the list 添加新的细胞nodes（表示新开始的序列）\n",
    "                    cell_starts.append(i)\n",
    "\n",
    "            if num_starts > 0:  #说明有新的细胞轨迹\n",
    "                df_parents.append(self.find_parent_cell(frame_ind, all_frames_traject, df, num_starts, cell_starts))\n",
    "            all_trajectory_dict[frame_ind] = {'from': nodes_indices, 'to': next_frame_indices}\n",
    "\n",
    "        all_frames_traject = all_frames_traject.astype(int)\n",
    "\n",
    "        # create csv contains all the relevant information for the res_track.txt\n",
    "        df_parents_all = pd.concat(df_parents, axis=0).reset_index(drop=True)\n",
    "        df_track_res, trajectory_same_label = self.set_all_info(df_parents_all, all_frames_traject)\n",
    "\n",
    "        # convert csv to res_track.txt and res_track_real.txt\n",
    "        str_track = self.df2str(df_track_res)\n",
    "\n",
    "        # convert all_frames_traject to csv\n",
    "        df_trajectory = pd.DataFrame(all_frames_traject)\n",
    "\n",
    "\n",
    "        self.all_frames_traject = all_frames_traject\n",
    "        self.trajectory_same_label = trajectory_same_label\n",
    "        self.df_trajectory = df_trajectory\n",
    "        self.df_track = df_track_res\n",
    "        self.file_str = str_track\n",
    "\n",
    "        return all_frames_traject, trajectory_same_label, \\\n",
    "               df_trajectory,  \\\n",
    "               str_track\n",
    "\n",
    "    def get_pred(self, idx):\n",
    "        pred = None\n",
    "        if len(self.results):\n",
    "            im_path = self.results[idx]\n",
    "            pred = io.imread(im_path)\n",
    "            if self.is_3d and len(pred.shape) != 3:\n",
    "                pred = np.stack(imageio.mimread(im_path))\n",
    "                assert len(pred.shape) == 3, f\"Expected 3d dimiension! but {pred.shape}\"\n",
    "        return pred\n",
    "\n",
    "    def create_save_dir(self):\n",
    "        num_seq = self.dir_result.split('/')[-1][:2]\n",
    "        save_tra_dir = osp.join(self.dir_result, f\"../{num_seq}_RES\")\n",
    "        self.save_tra_dir =save_tra_dir\n",
    "        os.makedirs(self.save_tra_dir, exist_ok=True)\n",
    "\n",
    "    def save_new_pred(self, new_pred, idx):\n",
    "        idx_str = \"%03d\" % idx\n",
    "        file_name = f\"mask{idx_str}.tif\"\n",
    "        full_dir = osp.join(self.save_tra_dir, file_name)\n",
    "        io.imsave(full_dir, new_pred.astype(np.uint16))\n",
    "\n",
    "    def check_ids_consistent(self, frame_ind, pred_ids, curr_ids):\n",
    "\n",
    "        predID_not_in_currID = [x for x in pred_ids if x not in curr_ids]\n",
    "        currID_not_in_predID = [x for x in curr_ids if x not in pred_ids]\n",
    "        flag1 = len(predID_not_in_currID) == 1 and predID_not_in_currID[0] == 0\n",
    "        flag2 = len(currID_not_in_predID) == 0\n",
    "        if not flag2:\n",
    "            # print('pred_ids', pred_ids)\n",
    "            # print('curr_ids:', curr_ids)\n",
    "            print('currID_not_in_predID', currID_not_in_predID)\n",
    "        if not flag1:\n",
    "            str_print = f\"Frame {frame_ind}: Find segmented cell {predID_not_in_currID} without assigned labels\"\n",
    "            warnings.warn(str_print)\n",
    "            #change\n",
    "        # assert flag2, f\"Frame {frame_ind}: Find assigned labels {currID_not_in_predID} \" \\\n",
    "        #               f\"which are not appears in the final saved results\"\n",
    "        flag1 = 0\n",
    "        flag2 = 0\n",
    "\n",
    "        return flag1, predID_not_in_currID\n",
    "\n",
    "    def fix_inconsistent(self, pred_prob_ids, pred):\n",
    "        for id in pred_prob_ids:\n",
    "            if id == 0:\n",
    "                continue\n",
    "            pred[pred == id] = 0\n",
    "        return pred\n",
    "\n",
    "    def fill_mask_labels(self, debug=False):\n",
    "        self.create_save_dir()\n",
    "        all_frames_traject, trajectory_same_label = self.all_frames_traject, self.trajectory_same_label\n",
    "        df = self.df_preds\n",
    "        n_rows, n_cols = all_frames_traject.shape\n",
    "        self.flag_id0_terminate = True\n",
    "        #change\n",
    "\n",
    "        count_diff_vals = 0\n",
    "        for idx in range(n_rows):\n",
    "            pred = self.get_pred(idx)#得到相应帧数的图片\n",
    "            pred_copy = pred.copy()\n",
    "            curr_row = all_frames_traject[idx, :]#得到当前行\n",
    "            mask_id = np.bitwise_and(curr_row != -1, curr_row != -2)#选取不为空的元素位置\n",
    "            graph_ids = curr_row[mask_id]#得到mask值（all_frames_traject）\n",
    "            graph_true_ids = trajectory_same_label[idx, mask_id]#same_id里面得到（即轨迹的结束ID）\n",
    "            mask_where = np.ones_like(pred)#设置0和1的图像（保存位置\n",
    "            frame_ids = []\n",
    "            for id, true_id in zip(graph_ids, graph_true_ids):\n",
    "                #id mask 的唯一标识\n",
    "                #true_id 要修改的值\n",
    "                flag_id0 = true_id == 0\n",
    "                if flag_id0:    # edge case when the cell with id=0 terminate after one frame\n",
    "                    if self.flag_id0_terminate:\n",
    "                        new_id = trajectory_same_label.max() + 1\n",
    "                        self.df_track.child_id[self.df_track.child_id == 0] = new_id#修改trueID=0为newID\n",
    "                        self.file_str = self.df2str(self.df_track)\n",
    "                    else:\n",
    "                        assert False, \"Problem!\"\n",
    "                if self.is_3d:\n",
    "                    cell_center = df.loc[id, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values.astype(int)\n",
    "                    depth_center, row_center, col_center = cell_center[0], cell_center[1], cell_center[2]\n",
    "                    if self.center_coord:\n",
    "                        n_depth_img, n_row_img, n_col_img = pred.shape\n",
    "                        depth_center += n_depth_img // 2\n",
    "                        row_center += n_row_img // 2\n",
    "                        col_center += n_col_img // 2\n",
    "\n",
    "                    val = pred[depth_center, row_center, col_center]\n",
    "                    if 'seg_label' in df.columns:\n",
    "                        v_old = val\n",
    "                        val = df.loc[id, \"seg_label\"]\n",
    "                        count_diff_vals += 1 if v_old != val else 0\n",
    "\n",
    "                    if val == 0:\n",
    "                        if np.any(pred[depth_center-3:depth_center+3, row_center-3:row_center+3, col_center-3:col_center+3] != 0):\n",
    "                            area = pred[depth_center-3:depth_center+3, row_center-3:row_center+3, col_center-3:col_center+3]\n",
    "                            unique_labels, counts = np.unique(area, return_counts=True)\n",
    "                            mask = unique_labels != 0\n",
    "                            unique_labels = unique_labels[mask]\n",
    "                            counts = counts[mask]\n",
    "                            val = unique_labels[np.argmax(counts)]\n",
    "                        else:\n",
    "                            print(\"Problem! The provided center coordinates value is zero, should be labeled with other value\")\n",
    "                            print(df.loc[id, [\"seg_label\", \"frame_num\",  \"centroid_depth\", \"centroid_row\", \"centroid_col\", \"min_depth_bb\",\n",
    "                                              \"min_row_bb\", \"min_col_bb\", \"max_depth_bb\", \"max_row_bb\", \"max_col_bb\"]].astype(int))\n",
    "                            print()\n",
    "                            continue\n",
    "                else:\n",
    "                    cell_center = df.loc[id, [\"centroid_row\", \"centroid_col\"]].values.astype(int)#通过df找到中心位置\n",
    "                    row_center, col_center = cell_center[0], cell_center[1]\n",
    "                    if self.center_coord:\n",
    "                        n_row_img, n_col_img = pred.shape\n",
    "                        row_center += n_row_img // 2\n",
    "                        col_center += n_col_img // 2\n",
    "\n",
    "                    val = pred[row_center, col_center]\n",
    "                    if 'seg_label' in df.columns:\n",
    "                        v_old = val\n",
    "                        val = df.loc[id, \"seg_label\"]\n",
    "                        count_diff_vals += 1 if v_old != val else 0\n",
    "\n",
    "                    if val == 0:\n",
    "                        print('val = 0')\n",
    "                        if np.any(pred[row_center-3:row_center+3, col_center-3:col_center+3] != 0):\n",
    "                            area = pred[row_center-3:row_center+3, col_center-3:col_center+3]\n",
    "                            unique_labels, counts = np.unique(area, return_counts=True)\n",
    "                            mask = unique_labels != 0\n",
    "                            unique_labels = unique_labels[mask]\n",
    "                            counts = counts[mask]\n",
    "                            val = unique_labels[np.argmax(counts)]\n",
    "                        else:\n",
    "                            print(\n",
    "                                \"Problem! The provided center coordinates value is zero, should be labeled with other value\")\n",
    "                            print(df.loc[id, [\"seg_label\", \"frame_num\", \"centroid_row\", \"centroid_col\",\n",
    "                                              \"min_row_bb\", \"min_col_bb\", \"max_row_bb\", \"max_col_bb\"]].astype(int))\n",
    "                            print()\n",
    "                            continue\n",
    "                        #这段代码检查 val 是否等于 0，如果是，则说明当前像素点的预测值为 0。在这种情况下，代码尝试找到周围 3x3 区域内非零的像素值，并选择其中最常出现的像素值作为新的 val。\n",
    "\n",
    "                assert val != 0, \"Problem! The provided center coordinates value is zero, \" \\\n",
    "                                 \"should be labeled with other value\"\n",
    "                if flag_id0:\n",
    "                    true_id = new_id\n",
    "                mask_val = (pred_copy == val).copy()\n",
    "                mask_curr = np.logical_and(mask_val, mask_where)\n",
    "                pred_copy[mask_curr] = true_id\n",
    "                # if not np.any(mask_curr):\n",
    "                #     print('empty1')\n",
    "                # if idx == 4 :\n",
    "                #     plt.subplot(2,2,3)\n",
    "                #     plt.imshow(pred_copy)\n",
    "                #     if true_id == 113:\n",
    "                #         if not np.any(mask_curr):\n",
    "                #             print('empty2')\n",
    "                #         plt.subplot(2,2,1)\n",
    "                #         plt.imshow(pred_copy)\n",
    "                #         plt.subplot(2,2,2)\n",
    "                #         plt.imshow(mask_curr)\n",
    "                #         # plt.show()\n",
    "\n",
    "                mask_where = np.logical_and(np.logical_not(mask_val), mask_where)\n",
    "\n",
    "                frame_ids.append(true_id)\n",
    "\n",
    "            isOK, predID_not_in_currID = self.check_ids_consistent(idx, np.unique(pred_copy), frame_ids)\n",
    "            if not debug:\n",
    "                if not isOK:\n",
    "                    pred_copy = self.fix_inconsistent(predID_not_in_currID, pred_copy)\n",
    "                self.save_new_pred(pred_copy, idx)\n",
    "        print(f\"Number of different vals: {count_diff_vals}\")\n",
    "        self.save_txt(self.file_str, self.save_tra_dir, 'res_track.txt')\n",
    "\n",
    "\n",
    "modality = '2D'\n",
    "path_inference_output = '/data/sunrui/celldata/r03c06f04ch1/01_RES_inference'\n",
    "path_Seg_result = '/data/sunrui/celldata/r03c06f04ch1/01_GT/SEG/'\n",
    "is_3d = '3d' in modality.lower()\n",
    "directed = True\n",
    "merge_operation = 'AND'\n",
    "pp = Postprocess(is_3d=is_3d,\n",
    "                    type_masks='tif', merge_operation=merge_operation,\n",
    "                    decision_threshold=0.5,\n",
    "                    path_inference_output=path_inference_output, center_coord=False,\n",
    "                    directed=directed,\n",
    "                    path_seg_result=path_Seg_result)\n",
    "\n",
    "all_frames_traject, trajectory_same_label, df_trajectory, str_track = pp.create_trajectory()\n",
    "pp.fill_mask_labels(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /data/sunrui/celldata/r03c06f04ch1/01_RES_inference/pytorch_geometric_data.pt\n",
      "Load /data/sunrui/celldata/r03c06f04ch1/01_RES_inference/all_data_df.csv\n",
      "Load /data/sunrui/celldata/r03c06f04ch1/01_RES_inference/raw_output.pt\n",
      "tensor([[    0,     1,     2,  ..., 16137, 16139, 16146],\n",
      "        [   53,    55,    54,  ..., 16167, 16154, 16171]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 14\u001b[0m\n\u001b[1;32m      6\u001b[0m merge_operation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAND\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      7\u001b[0m pp \u001b[39m=\u001b[39m Postprocess(is_3d\u001b[39m=\u001b[39mis_3d,\n\u001b[1;32m      8\u001b[0m                     type_masks\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtif\u001b[39m\u001b[39m'\u001b[39m, merge_operation\u001b[39m=\u001b[39mmerge_operation,\n\u001b[1;32m      9\u001b[0m                     decision_threshold\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[1;32m     10\u001b[0m                     path_inference_output\u001b[39m=\u001b[39mpath_inference_output, center_coord\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                     directed\u001b[39m=\u001b[39mdirected,\n\u001b[1;32m     12\u001b[0m                     path_seg_result\u001b[39m=\u001b[39mpath_Seg_result)\n\u001b[0;32m---> 14\u001b[0m all_frames_traject, trajectory_same_label, df_trajectory, str_track \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39;49mcreate_trajectory()\n\u001b[1;32m     15\u001b[0m pp\u001b[39m.\u001b[39mfill_mask_labels(debug\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[28], line 324\u001b[0m, in \u001b[0;36mPostprocess.create_trajectory\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m next_frame_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(next_frame_indices, next_node_ind)\u001b[39m#保存连接结果\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39m# count the number of starting trajectories\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m start, all_frames_traject \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minsert_in_specific_col(all_frames_traject, frame_ind, i, next_node_ind)\n\u001b[1;32m    325\u001b[0m num_starts \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m start\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m start \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:  \u001b[39m# append the id of the cell to the list 添加新的细胞nodes（表示新开始的序列）\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 72\u001b[0m, in \u001b[0;36mPostprocess.insert_in_specific_col\u001b[0;34m(self, all_frames_traject, frame_ind, curr_node, next_node)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m curr_node \u001b[39min\u001b[39;00m all_frames_traject[frame_ind, :]:\n\u001b[1;32m     71\u001b[0m     flag \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 72\u001b[0m     ind_place \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margwhere(all_frames_traject[frame_ind, :] \u001b[39m==\u001b[39;49m curr_node)\n\u001b[1;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m frame_ind \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m all_frames_traject\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m     74\u001b[0m         all_frames_traject[frame_ind \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, ind_place] \u001b[39m=\u001b[39m next_node\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/cell-tracking-challenge/lib/python3.8/site-packages/numpy/core/numeric.py:614\u001b[0m, in \u001b[0;36margwhere\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39mFind the indices of array elements that are non-zero, grouped by element.\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m \n\u001b[1;32m    612\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[39m# nonzero does not behave well on 0d, so promote to 1d\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39;49mndim(a) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    615\u001b[0m     a \u001b[39m=\u001b[39m shape_base\u001b[39m.\u001b[39matleast_1d(a)\n\u001b[1;32m    616\u001b[0m     \u001b[39m# then remove the added dimension\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modality = '2D'\n",
    "path_inference_output = '/data/sunrui/celldata/r03c06f04ch1/01_RES_inference'\n",
    "path_Seg_result = '/data/sunrui/celldata/r03c06f04ch1/01_GT/SEG/'\n",
    "is_3d = '3d' in modality.lower()\n",
    "directed = True\n",
    "merge_operation = 'AND'\n",
    "pp = Postprocess(is_3d=is_3d,\n",
    "                    type_masks='tif', merge_operation=merge_operation,\n",
    "                    decision_threshold=0.5,\n",
    "                    path_inference_output=path_inference_output, center_coord=False,\n",
    "                    directed=directed,\n",
    "                    path_seg_result=path_Seg_result)\n",
    "\n",
    "all_frames_traject, trajectory_same_label, df_trajectory, str_track = pp.create_trajectory()\n",
    "pp.fill_mask_labels(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     0,     0,  ..., 16146, 16146, 16146],\n",
      "        [   53,    55,    74,  ..., 16154, 16164, 16171]])\n",
      "tensor([[    0,     1,     2,  ..., 16137, 16139, 16146],\n",
      "        [   53,    55,    54,  ..., 16167, 16154, 16171]])\n"
     ]
    }
   ],
   "source": [
    "x1,x2 = pp.test()\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     1     2 ...    -2    -2    -2]\n",
      " [   53    55    54 ...    -2    -2    -2]\n",
      " [  110   109    -1 ...    -2    -2    -2]\n",
      " ...\n",
      " [16088 16082 16101 ...    -2    -2    -2]\n",
      " [16124 16118 16139 ...    -2    -2    -2]\n",
      " [16158 16151 16154 ...    -2    -2    -2]]\n"
     ]
    }
   ],
   "source": [
    "print(all_frames_traject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_same_label\n",
    "df_same_tra = pd.DataFrame(trajectory_same_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_same_tra.to_csv(\"/data/sunrui/celldata/r03c06f04ch1/df_same_tra.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>-1</td>\n",
       "      <td>111</td>\n",
       "      <td>159</td>\n",
       "      <td>114</td>\n",
       "      <td>112</td>\n",
       "      <td>119</td>\n",
       "      <td>115</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167</td>\n",
       "      <td>166</td>\n",
       "      <td>-2</td>\n",
       "      <td>168</td>\n",
       "      <td>213</td>\n",
       "      <td>170</td>\n",
       "      <td>171</td>\n",
       "      <td>180</td>\n",
       "      <td>169</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>224</td>\n",
       "      <td>223</td>\n",
       "      <td>270</td>\n",
       "      <td>222</td>\n",
       "      <td>262</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>228</td>\n",
       "      <td>226</td>\n",
       "      <td>241</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>16028</td>\n",
       "      <td>16023</td>\n",
       "      <td>16026</td>\n",
       "      <td>16020</td>\n",
       "      <td>16028</td>\n",
       "      <td>16028</td>\n",
       "      <td>16028</td>\n",
       "      <td>16039</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>16054</td>\n",
       "      <td>16047</td>\n",
       "      <td>16052</td>\n",
       "      <td>16059</td>\n",
       "      <td>16054</td>\n",
       "      <td>16054</td>\n",
       "      <td>16054</td>\n",
       "      <td>16069</td>\n",
       "      <td>16049</td>\n",
       "      <td>16051</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>16088</td>\n",
       "      <td>16082</td>\n",
       "      <td>16101</td>\n",
       "      <td>16106</td>\n",
       "      <td>16088</td>\n",
       "      <td>16088</td>\n",
       "      <td>16088</td>\n",
       "      <td>16103</td>\n",
       "      <td>16086</td>\n",
       "      <td>16092</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>16124</td>\n",
       "      <td>16118</td>\n",
       "      <td>16139</td>\n",
       "      <td>16138</td>\n",
       "      <td>16124</td>\n",
       "      <td>16124</td>\n",
       "      <td>16124</td>\n",
       "      <td>16135</td>\n",
       "      <td>16125</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>16158</td>\n",
       "      <td>16151</td>\n",
       "      <td>16154</td>\n",
       "      <td>-1</td>\n",
       "      <td>16158</td>\n",
       "      <td>16158</td>\n",
       "      <td>16158</td>\n",
       "      <td>16166</td>\n",
       "      <td>-1</td>\n",
       "      <td>16150</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9   \\\n",
       "0        0      1      2      3      4      5      6      7      8      9   \n",
       "1       53     55     54     56     57     59     60     58     62     64   \n",
       "2      110    109     -1    111    159    114    112    119    115    121   \n",
       "3      167    166     -2    168    213    170    171    180    169    184   \n",
       "4      224    223    270    222    262    227    229    228    226    241   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "324  16028  16023  16026  16020  16028  16028  16028  16039     -1     -1   \n",
       "325  16054  16047  16052  16059  16054  16054  16054  16069  16049  16051   \n",
       "326  16088  16082  16101  16106  16088  16088  16088  16103  16086  16092   \n",
       "327  16124  16118  16139  16138  16124  16124  16124  16135  16125     -1   \n",
       "328  16158  16151  16154     -1  16158  16158  16158  16166     -1  16150   \n",
       "\n",
       "     ...  80  81  82  83  84  85  86  87  88  89  \n",
       "0    ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "1    ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "2    ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "3    ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "4    ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "324  ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "325  ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "326  ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "327  ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "328  ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "\n",
       "[329 rows x 90 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_trajectory.to_csv(\"/data/sunrui/celldata/r03c06f04ch1/df_tra.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1912 0 36 0\\n8318 0 151 0\\n8354 0 151 0\\n12449 0 227 0\\n8327 0 151 0\\n15765 0 315 0\\n12400 0 225 0\\n8321 0 151 0\\n8324 0 151 0\\n8362 0 151 0\\n8328 0 151 0\\n8350 0 151 0\\n12432 0 226 0\\n3711 0 69 0\\n8346 0 151 0\\n8333 0 151 0\\n8332 0 151 0\\n2978 0 56 0\\n8330 0 151 0\\n15319 0 302 0\\n8326 0 151 0\\n8336 0 151 0\\n8343 0 151 0\\n8319 0 151 0\\n16149 0 328 0\\n8344 0 151 0\\n8329 0 151 0\\n8369 0 151 0\\n2016 0 37 0\\n8338 0 151 0\\n8339 0 151 0\\n8356 0 151 0\\n597 0 10 0\\n607 0 10 0\\n441 1 7 0\\n609 1 10 0\\n372 4 6 0\\n611 8 10 441\\n553 9 9 0\\n769 11 13 611\\n8341 12 151 0\\n8371 12 151 0\\n934 15 16 0\\n1403 25 25 0\\n8352 28 151 0\\n8357 28 151 0\\n1758 32 32 0\\n2535 47 47 0\\n2589 49 49 0\\n8359 50 151 2589\\n2975 52 55 0\\n8358 62 151 0\\n3691 63 68 0\\n3412 63 63 0\\n3650 67 67 0\\n4050 71 74 0\\n8351 72 151 0\\n8337 74 151 0\\n4161 76 76 0\\n8355 78 151 0\\n4267 78 78 0\\n4323 79 79 4267\\n4432 80 81 4323\\n4434 81 82 0\\n4544 84 84 0\\n8379 84 152 0\\n8347 84 151 0\\n4711 86 86 0\\n4829 87 88 4711\\n4827 88 88 0\\n6274 95 115 0\\n8353 102 151 0\\n8361 105 151 0\\n6444 118 118 0\\n6556 119 120 6444\\n6558 120 120 0\\n8368 121 151 6558\\n6672 122 122 0\\n6725 123 123 6672\\n7057 128 128 0\\n7411 129 135 7057\\n7173 129 130 7057\\n7180 131 131 7173\\n7187 131 131 7173\\n8345 132 151 7180\\n7620 132 138 7180\\n8360 132 151 7180\\n7466 135 135 0\\n7865 137 143 0\\n8348 140 151 0\\n8366 140 151 0\\n8372 142 151 0\\n8363 143 151 0\\n8367 143 151 0\\n8364 146 151 0\\n8349 148 151 0\\n8370 149 151 0\\n8316 150 151 0\\n8342 150 151 0\\n8322 151 151 0\\n12309 153 223 8379\\n15408 153 304 8379\\n14421 153 278 8379\\n15093 153 296 8379\\n16164 153 328 8379\\n16161 153 328 8379\\n15168 153 298 8379\\n13233 153 245 8379\\n16150 153 328 8379\\n9888 153 178 8379\\n16155 153 328 8379\\n14107 153 268 8379\\n16162 153 328 8379\\n8496 153 154 8379\\n8498 155 155 8496\\n8618 156 157 8498\\n8666 156 157 8498\\n8667 156 157 8498\\n8662 157 157 0\\n8669 158 158 8667\\n10081 159 181 8669\\n10085 159 181 8669\\n9033 163 163 0\\n9036 163 163 0\\n9526 166 172 0\\n9280 166 167 0\\n11478 171 207 0\\n10116 173 181 9526\\n10109 176 181 0\\n16151 183 328 0\\n10381 183 186 0\\n10316 185 185 0\\n10378 185 186 0\\n10434 185 187 0\\n10489 188 188 10434\\n10541 189 189 10489\\n10545 189 189 10489\\n10546 189 189 10489\\n10818 191 194 0\\n10824 191 194 0\\n10823 194 194 0\\n10869 195 195 10823\\n10900 196 196 10869\\n10977 196 197 10869\\n11089 199 199 0\\n11988 201 216 0\\n11636 210 210 0\\n12081 212 218 0\\n14007 216 265 0\\n12084 218 218 0\\n12268 220 222 0\\n12356 220 224 0\\n12177 221 221 0\\n12223 222 222 12177\\n16158 224 328 12309\\n12494 225 227 12356\\n12450 227 227 12432\\n12572 229 229 0\\n12700 230 232 12572\\n13329 230 247 12572\\n12618 231 231 0\\n12834 233 236 12700\\n12913 236 237 0\\n13289 238 246 12913\\n12998 239 239 0\\n13005 239 239 0\\n13132 241 243 0\\n13215 244 245 13132\\n13293 244 247 13132\\n13209 244 244 13132\\n13252 245 246 13209\\n13264 246 246 13215\\n13276 246 246 13233\\n13288 246 246 13215\\n13291 246 246 13215\\n13292 246 246 13233\\n13367 247 248 13264\\n13489 250 251 0\\n13571 250 253 0\\n13572 253 253 0\\n13574 254 254 13571\\n13717 256 257 0\\n13679 256 256 0\\n13720 258 258 13717\\n16148 258 328 13717\\n13754 258 258 13717\\n13757 258 258 13717\\n13851 261 261 0\\n13860 261 261 0\\n13929 262 263 13851\\n14077 262 267 13860\\n14351 263 275 0\\n14142 263 269 0\\n13930 263 263 0\\n14011 264 266 13930\\n13961 264 264 13929\\n14074 265 267 13961\\n14008 265 265 13961\\n14247 268 273 14074\\n14108 268 268 14074\\n14316 269 274 14108\\n16160 269 328 14108\\n14341 270 275 14142\\n14348 271 275 0\\n14241 272 272 0\\n15240 274 299 14247\\n14381 276 277 14348\\n14416 276 277 14348\\n14380 276 276 14348\\n16166 277 328 14380\\n14486 279 279 14421\\n14491 279 279 14421\\n14600 282 282 0\\n14603 282 282 0\\n16147 285 328 0\\n14754 286 286 0\\n14795 287 287 14754\\n14828 288 288 14795\\n14865 289 289 14828\\n14976 289 292 14828\\n14974 291 292 0\\n15475 294 306 0\\n15326 295 302 0\\n15166 298 298 0\\n15234 299 299 15166\\n16119 300 327 15240\\n16152 300 328 15240\\n15346 300 302 15240\\n15350 302 302 0\\n15458 304 306 0\\n15460 304 306 0\\n15388 304 304 0\\n15444 304 305 0\\n15478 304 306 0\\n15480 306 307 15444\\n16154 308 328 15480\\n15801 308 316 15480\\n15521 308 308 15480\\n15802 308 316 15480\\n15777 310 316 0\\n15680 311 313 0\\n15992 313 323 0\\n15988 314 323 15680\\n15800 315 316 0\\n15792 316 316 15765\\n15905 318 320 0\\n15901 318 320 0\\n16165 318 328 0\\n15932 318 320 0\\n15931 318 320 0\\n15930 318 320 0\\n15929 319 320 0\\n15933 319 320 0\\n16157 322 328 0\\n16143 323 327 0\\n16144 323 327 0\\n16170 323 328 0\\n16007 323 323 0\\n16167 323 328 0\\n16010 323 323 0\\n16015 323 323 0\\n16145 324 327 15988\\n16125 325 327 0\\n16156 325 328 0\\n16140 325 327 0\\n16076 325 325 0\\n16159 326 328 16076\\n16171 327 328 0\\n16153 328 328 16144\\n16163 328 328 16145\\n16168 328 328 16145\\n16169 328 328 16145\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for frame_ind in frame_nums:\n",
    "#     mask_frame_ind = df.frame_num.isin([frame_ind])  # 找到包含特定帧编号的位置\n",
    "\n",
    "#     # 过滤出特定帧编号的位置，并获取相应的节点数据\n",
    "#     nodes = df.loc[mask_frame_ind, :]\n",
    "#     nodes_indices = nodes.index.values\n",
    "\n",
    "#     next_frame_indices = np.array([])\n",
    "\n",
    "#     if frame_ind == 0:  # 对于第一帧，需要用节点索引填充第一行\n",
    "#         all_frames_traject[frame_ind, :nodes_indices.shape[0]] = nodes_indices\n",
    "#         df_parents.append(self.fill_first_frame(nodes_indices))\n",
    "\n",
    "#     num_starts = 0\n",
    "#     cell_starts = []\n",
    "    \n",
    "#     # 遍历当前帧的每个节点\n",
    "#     for i in nodes_indices:\n",
    "#         if i in connected_indices[0, :]:  # 如果当前节点连接到下一帧的节点\n",
    "#             ind_place = np.argwhere(connected_indices[0, :] == i)\n",
    "\n",
    "#             if ind_place.shape[-1] > 1:  # 当前节点连接多个下一帧的节点\n",
    "#                 next_frame_ind = connected_indices[1, ind_place].numpy().squeeze()\n",
    "#                 if self.is_3d:\n",
    "#                     next_frame = df.loc[next_frame_ind, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "#                     curr_node = df.loc[i, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "#                 else:\n",
    "#                     next_frame = df.loc[next_frame_ind, [\"centroid_row\", \"centroid_col\"]].values\n",
    "#                     curr_node = df.loc[i, [\"centroid_row\", \"centroid_col\"]].values\n",
    "\n",
    "#                 distance = ((next_frame - curr_node) ** 2).sum(axis=-1)\n",
    "#                 nearest_cell = np.argmin(distance, axis=-1)\n",
    "#                 next_node_ind = next_frame_ind[nearest_cell]\n",
    "\n",
    "#             elif ind_place.shape[-1] == 1:  # 当前节点连接一个下一帧的节点\n",
    "#                 next_node_ind = connected_indices[1, ind_place[0]]\n",
    "#             else:  # 没有节点连接到当前节点，结束轨迹\n",
    "#                 next_node_ind = -1\n",
    "\n",
    "#         else:\n",
    "#             # 当前节点在边索引矩阵中没有连接节点 - 表示没有连接\n",
    "#             # 对于节点 i == 0 的情况，结束轨迹\n",
    "#             if i == 0:\n",
    "#                 self.flag_id0_terminate = True\n",
    "#             next_node_ind = -1\n",
    "\n",
    "#         next_frame_indices = np.append(next_frame_indices, next_node_ind)\n",
    "        \n",
    "#         # 计算开始轨迹的数量并更新轨迹矩阵\n",
    "#         start, all_frames_traject = self.insert_in_specific_col(all_frames_traject, frame_ind, i, next_node_ind)\n",
    "#         num_starts += start\n",
    "\n",
    "#         if start == 1:  # 将细胞的 ID 添加到列表中\n",
    "#             cell_starts.append(i)\n",
    "\n",
    "#     # 如果存在开始的轨迹，找到并添加父细胞的信息\n",
    "#     if num_starts > 0:\n",
    "#         df_parents.append(self.find_parent_cell(frame_ind, all_frames_traject, df, num_starts, cell_starts))\n",
    "    \n",
    "#     # 为当前帧添加轨迹信息到字典中\n",
    "#     all_trajectory_dict[frame_ind] = {'from': nodes_indices, 'to': next_frame_indices}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -modality MODALITY -iseg ISEG -oi OI\n",
      "ipykernel_launcher.py: error: the following arguments are required: -modality, -iseg, -oi\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__== \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-modality', type=str, required=True, help='2D/3D modality')\n",
    "    parser.add_argument('-iseg', type=str, required=True, help='segmentation output directory')\n",
    "    parser.add_argument('-oi', type=str, required=True, help='inference output directory')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    modality = args.modality\n",
    "    assert modality == '2D' or modality == '3D'\n",
    "\n",
    "    path_inference_output = args.oi\n",
    "    path_Seg_result = args.iseg\n",
    "\n",
    "    is_3d = '3d' in modality.lower()\n",
    "    directed = True\n",
    "    merge_operation = 'AND'\n",
    "\n",
    "    pp = Postprocess(is_3d=is_3d,\n",
    "                     type_masks='tif', merge_operation=merge_operation,\n",
    "                     decision_threshold=0.5,\n",
    "                     path_inference_output=path_inference_output, center_coord=False,\n",
    "                     directed=directed,\n",
    "                     path_seg_result=path_Seg_result)\n",
    "    all_frames_traject, trajectory_same_label, df_trajectory, str_track = pp.create_trajectory()\n",
    "    pp.fill_mask_labels(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell-tracking-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
