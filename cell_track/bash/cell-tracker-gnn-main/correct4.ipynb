{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunrui/anaconda3/envs/cell-tracking-challenge/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /data/sunrui/celldata/r03c06f04ch1/01_RES_inference/pytorch_geometric_data.pt\n",
      "Load /data/sunrui/celldata/r03c06f04ch1/01_RES_inference/all_data_df.csv\n",
      "Load /data/sunrui/celldata/r03c06f04ch1/01_RES_inference/raw_output.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Postprocess(object):\n",
    "    def __init__(self,\n",
    "                 is_3d,\n",
    "                 type_masks,\n",
    "                 merge_operation,\n",
    "                 decision_threshold,\n",
    "                 path_inference_output,\n",
    "                 center_coord,\n",
    "                 path_seg_result,\n",
    "                 directed=True\n",
    "                 ):\n",
    "\n",
    "        file1 = os.path.join(path_inference_output, 'pytorch_geometric_data.pt')\n",
    "        file2 = os.path.join(path_inference_output, 'all_data_df.csv')\n",
    "        file3 = os.path.join(path_inference_output, 'raw_output.pt')\n",
    "\n",
    "        self.dir_result = dir_results = path_seg_result\n",
    "        self.results = []\n",
    "        if os.path.exists(dir_results):\n",
    "            self.results = [os.path.join(dir_results, fname) for fname in sorted(os.listdir(dir_results))\n",
    "                            if type_masks in fname]\n",
    "\n",
    "        self.is_3d = is_3d\n",
    "        self.center_coord = center_coord\n",
    "        self.merge_operation = merge_operation\n",
    "        self.decision_threshold = decision_threshold\n",
    "        self.directed = directed\n",
    "        self.path_inference_output = path_inference_output\n",
    "        self.cols = [\"child_id\", \"parent_id\", \"start_frame\"]\n",
    "\n",
    "        data = self._load_file(file1)\n",
    "        self.edge_index = data.edge_index\n",
    "\n",
    "        self.df_preds = self._load_file(file2)\n",
    "        self.output_pred = self._load_file(file3)\n",
    "        self.find_connected_edges()\n",
    "\n",
    "    def _load_file(self, file_path):\n",
    "        print(f\"Load {file_path}\")\n",
    "        file_type = file_path.split('.')[-1]\n",
    "        if file_type == 'csv':\n",
    "            file = pd.read_csv(file_path, index_col=0)\n",
    "        if file_type == 'pt':\n",
    "            file = torch.load(file_path)\n",
    "        return file\n",
    "\n",
    "    def save_csv(self, df_file, file_name):\n",
    "        full_name = os.path.join(self.path_inference_output, f\"postprocess_data\")\n",
    "        os.makedirs(full_name, exist_ok=True)\n",
    "        full_name = os.path.join(full_name, file_name)\n",
    "        df_file.to_csv(full_name)\n",
    "\n",
    "    def save_txt(self, str_txt, output_folder, file_name):\n",
    "        full_name = os.path.join(output_folder, file_name)\n",
    "        with open(full_name, \"w\") as text_file:\n",
    "            text_file.write(str_txt)\n",
    "\n",
    "    def insert_in_specific_col(self, all_frames_traject, frame_ind, curr_node, next_node):\n",
    "        if curr_node in all_frames_traject[frame_ind, :]:\n",
    "            flag = 0\n",
    "            ind_place = np.argwhere(all_frames_traject[frame_ind, :] == curr_node)\n",
    "            if frame_ind + 1 < all_frames_traject.shape[0]:\n",
    "                all_frames_traject[frame_ind + 1, ind_place] = next_node\n",
    "        else:\n",
    "            flag = 1\n",
    "            ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -2)\n",
    "            while ind_place.size == 0:\n",
    "                new_col = -2 * np.ones((all_frames_traject.shape[0], 1), dtype=all_frames_traject.dtype)\n",
    "                all_frames_traject = np.append(all_frames_traject, new_col, axis=1)\n",
    "                ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -2)\n",
    "            ind_place = ind_place.min()\n",
    "            all_frames_traject[frame_ind, ind_place] = curr_node\n",
    "            if frame_ind + 1 < all_frames_traject.shape[0]:\n",
    "                all_frames_traject[frame_ind + 1, ind_place] = next_node\n",
    "\n",
    "        return flag, all_frames_traject\n",
    "\n",
    "    def fill_first_frame(self, cell_starts):\n",
    "        cols = [\"child_id\", \"parent_id\", \"start_frame\"]\n",
    "        df_parent = pd.DataFrame(index=range(len(list(cell_starts))), columns=cols)\n",
    "        df_parent.loc[:, [\"start_frame\", \"parent_id\"]] = 0\n",
    "        df_parent.loc[:, \"child_id\"] = cell_starts\n",
    "        return df_parent\n",
    "\n",
    "    def find_parent_cell(self, frame_ind, all_frames_traject, df, num_starts, cell_starts):\n",
    "        ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -1)#轨迹结束位置\n",
    "        finish_node_ids = all_frames_traject[frame_ind - 1, ind_place].squeeze(axis=1)#轨迹结束的位置与结束的nodes\n",
    "        # print(f\"frame_ind: {frame_ind}, cell_starts: {cell_starts}, cell_ends: {finish_node_ids}\")\n",
    "\n",
    "        df_parent = pd.DataFrame(index=range(len(cell_starts)), columns=self.cols)\n",
    "        df_parent.loc[:, \"start_frame\"] = frame_ind#存在新细胞轨迹，保存开始帧数\n",
    "\n",
    "        if finish_node_ids.shape[0] != 0:#存在轨迹结束\n",
    "            if self.is_3d:\n",
    "                finish_cell = df.loc[finish_node_ids, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "            else:\n",
    "                finish_cell = df.loc[finish_node_ids, [\"centroid_row\", \"centroid_col\"]].values#保存结尾id中心位置\n",
    "            for ind, cell in enumerate(cell_starts):\n",
    "                if self.is_3d:\n",
    "                    curr_cell = df.loc[cell, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "                else:\n",
    "                    curr_cell = df.loc[cell, [\"centroid_row\", \"centroid_col\"]].values#保存新开始的细胞ID\n",
    "\n",
    "                distance = ((finish_cell - curr_cell) ** 2).sum(axis=-1)\n",
    "                nearest_cell = np.argmin(distance, axis=-1)\n",
    "                parent_cell = int(finish_node_ids[nearest_cell])#最近的结束细胞为亲代\n",
    "                df_parent.loc[ind, \"child_id\"] = cell\n",
    "                df_parent.loc[ind, \"parent_id\"] = parent_cell\n",
    "        else:\n",
    "            df_parent.loc[:, \"child_id\"] = cell_starts\n",
    "            df_parent.loc[:, \"parent_id\"] = 0\n",
    "\n",
    "        return df_parent\n",
    "\n",
    "    def clean_repetition(self, df):\n",
    "        all_childs = df.child_id.values\n",
    "        unique_vals, count_vals = np.unique(all_childs, return_counts=True)\n",
    "        prob_vals = unique_vals[count_vals > 1]\n",
    "        for prob_val in prob_vals:\n",
    "            masking = df.child_id.values == prob_val\n",
    "            all_apearence = df.loc[masking, :]\n",
    "            start_frame = all_apearence.start_frame.min()\n",
    "            end_frame = all_apearence.end_frame.max()\n",
    "            df.loc[all_apearence.index[0], [\"start_frame\", \"end_frame\"]] = start_frame, end_frame\n",
    "            df = df.drop(all_apearence.index[1:])\n",
    "\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "    def set_all_info(self, df_parents_all, all_frames_traject):\n",
    "\n",
    "        iterate_childs = df_parents_all.child_id.values\n",
    "        frames_traject_same_label = all_frames_traject.copy()\n",
    "        for ind, child_ind in enumerate(iterate_childs):\n",
    "            # find the place where we store the child_ind in the trajectory matrix\n",
    "            # validate that only one place exists\n",
    "            coordinates_child = np.argwhere(all_frames_traject == child_ind)\n",
    "            n_places = coordinates_child.shape[0]\n",
    "\n",
    "            assert n_places == 1, f\"Problem! find {n_places} places which the current child appears\"\n",
    "\n",
    "            coordinates_child = coordinates_child.squeeze()\n",
    "            row, col = coordinates_child\n",
    "            s_frame = df_parents_all.loc[ind, \"start_frame\"]\n",
    "            assert row == s_frame, f\"Problem! start frame {s_frame} is not equal to row {row}\"\n",
    "\n",
    "            # take the specific col from 'row' down\n",
    "            curr_col = all_frames_traject[row:, col]\n",
    "            last_ind = np.argwhere(curr_col == -1)\n",
    "            if last_ind.size != 0:\n",
    "                last_ind = last_ind[0].squeeze()\n",
    "                curr_col = curr_col[:last_ind]\n",
    "            e_frame = row + curr_col.shape[0] - 1\n",
    "\n",
    "            df_parents_all.loc[ind, \"end_frame\"] = int(e_frame)\n",
    "            # curr_id = curr_col[-1]#以最后一位结尾作为curr_id change\n",
    "            curr_id = curr_col[0]\n",
    "            # print(curr_id)\n",
    "            df_parents_all.loc[ind, \"child_id\"] = curr_id\n",
    "            frames_traject_same_label[row:e_frame + 1, col] = curr_id#以最后一位的node构建图像\n",
    "\n",
    "        assert not(df_parents_all.isnull().values.any()), \"Problem! dataframe contains NaN values\"\n",
    "        df_parents_all = self.clean_repetition(df_parents_all.astype(int))\n",
    "        return df_parents_all.astype(int), frames_traject_same_label#如果结尾在同一个mask上，则导致两条细胞轨迹为同一mask值\n",
    "\n",
    "    def df2str(self, df_track):\n",
    "        \"\"\"\n",
    "        L B E P where\n",
    "        L - a unique label of the track (label of markers, 16-bit positive value)\n",
    "        B - a zero-based temporal index of the frame in which the track begins\n",
    "        E - a zero-based temporal index of the frame in which the track ends\n",
    "        P - label of the parent track (0 is used when no parent is defined)\n",
    "        \"\"\"\n",
    "        str_track = ''\n",
    "        for i in df_track.index:\n",
    "            L = df_track.loc[i, \"child_id\"]\n",
    "            B = df_track.loc[i, \"start_frame\"]\n",
    "            E = df_track.loc[i, \"end_frame\"]\n",
    "            P = df_track.loc[i, \"parent_id\"]\n",
    "            str_track += f\"{L} {B} {E} {P}\\n\"\n",
    "\n",
    "        return str_track\n",
    "\n",
    "    def merge_edges(self):\n",
    "        in_output_pred, out_output_pred = self.match_edges()\n",
    "        if self.merge_operation == 'OR' or self.merge_operation == 'AND':\n",
    "            in_outputs_soft = torch.sigmoid(in_output_pred)\n",
    "            in_outputs_hard = (in_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            out_outputs_soft = torch.sigmoid(out_output_pred)\n",
    "            out_outputs_hard = (out_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            final_outputs_hard = np.bitwise_or(in_outputs_hard,out_outputs_hard) if self.merge_operation == 'OR'\\\n",
    "                else np.bitwise_and(in_outputs_hard,out_outputs_hard)\n",
    "\n",
    "        if self.merge_operation == 'AVG':\n",
    "            avg_outputs_soft = torch.sigmoid(in_output_pred) + torch.sigmoid(out_output_pred)\n",
    "            avg_outputs_soft = avg_outputs_soft / 2.0\n",
    "            final_outputs_hard = (avg_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "        self.outputs_hard = final_outputs_hard\n",
    "        return final_outputs_hard\n",
    "\n",
    "    def megre_match_edges(self, edge_index, output_pred):\n",
    "\n",
    "        assert torch.all(edge_index[:, ::2] == edge_index[[1, 0], 1::2]), \\\n",
    "            \"The results don't match!\"\n",
    "        edge_index = edge_index[:, ::2]\n",
    "        in_output_pred = output_pred[::2]\n",
    "        out_output_pred = output_pred[1::2]\n",
    "\n",
    "        if self.merge_operation == 'OR' or self.merge_operation == 'AND':\n",
    "            in_outputs_soft = torch.sigmoid(in_output_pred)\n",
    "            in_outputs_hard = (in_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            out_outputs_soft = torch.sigmoid(out_output_pred)\n",
    "            out_outputs_hard = (out_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            final_outputs_hard = np.bitwise_or(in_outputs_hard, out_outputs_hard) if self.merge_operation == 'OR' \\\n",
    "                else np.bitwise_and(in_outputs_hard, out_outputs_hard)\n",
    "\n",
    "        elif self.merge_operation == 'AVG':\n",
    "            avg_outputs_soft = torch.sigmoid(in_output_pred) + torch.sigmoid(out_output_pred)\n",
    "            avg_outputs_soft = avg_outputs_soft / 2.0\n",
    "            final_outputs_hard = (avg_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "        return final_outputs_hard, edge_index\n",
    "\n",
    "    def find_connected_edges(self):\n",
    "        edge_index, df, outputs = self.edge_index, self.df_preds, self.output_pred\n",
    "\n",
    "        if not self.directed:\n",
    "            final_outputs_hard, edge_index = self.megre_match_edges(edge_index.detach().clone(), outputs.detach().clone())\n",
    "            self.outputs_hard = final_outputs_hard\n",
    "            self.edge_index = edge_index\n",
    "        else:\n",
    "            outputs_soft = torch.sigmoid(outputs)\n",
    "            self.outputs_hard = (outputs_soft > self.decision_threshold).int()\n",
    "    \n",
    "    def test(self):\n",
    "        edge_index, df, outputs_hard = self.edge_index, self.df_preds, self.outputs_hard\n",
    "        connected_indices = edge_index[:, outputs_hard.bool()]\n",
    "        return edge_index, connected_indices\n",
    "\n",
    "    def create_trajectory(self):\n",
    "        edge_index, df, outputs_hard = self.edge_index, self.df_preds, self.outputs_hard\n",
    "        self.flag_id0_terminate = False\n",
    "        # extract values from arguments\n",
    "        connected_indices = edge_index[:, outputs_hard.bool()]#取出来符合要求的边缘\n",
    "        print(connected_indices)#change\n",
    "\n",
    "        # find number of frames for iterations\n",
    "        frame_nums = np.unique(df.frame_num)\n",
    "        # find number of cells in each frame and build matrix [num_frames, max_cells]\n",
    "        max_elements = [df.frame_num.isin([i]).sum() for i in frame_nums]\n",
    "        all_frames_traject = np.zeros((frame_nums.shape[0], max(max_elements)))\n",
    "        #创建轨迹图，横轴是帧数，纵轴是某一帧出现的最多细胞数 \n",
    "\n",
    "        # intialize the matrix with -2 meaning empty cell, -1 means end of trajectory,\n",
    "        # other value means the number of node in the graph\n",
    "        all_frames_traject[:, :] = -2\n",
    "        all_trajectory_dict = {}\n",
    "        str_track = ''\n",
    "        df_parents = []\n",
    "        for frame_ind in frame_nums:\n",
    "            mask_frame_ind = df.frame_num.isin([frame_ind])  # find the places containing frame_ind\n",
    "\n",
    "            # filter the places with the specific frame_ind and take the corresponding indices\n",
    "            nodes = df.loc[mask_frame_ind, :]\n",
    "            nodes_indices = nodes.index.values\n",
    "            #nodes_indices为当前帧的mask的唯一标识值\n",
    "\n",
    "            next_frame_indices = np.array([])\n",
    "\n",
    "            if frame_ind == 0:  # for the first frame, we should fill the first row with node indices\n",
    "                all_frames_traject[frame_ind, :nodes_indices.shape[0]] = nodes_indices\n",
    "                df_parents.append(self.fill_first_frame(nodes_indices))\n",
    "\n",
    "            num_starts = 0\n",
    "            cell_starts = []\n",
    "            for i in nodes_indices:\n",
    "                if i in connected_indices[0, :]:\n",
    "                    ind_place = np.argwhere(connected_indices[0, :] == i)\n",
    "\n",
    "                    if ind_place.shape[-1] > 1:\n",
    "                        next_frame_ind = connected_indices[1, ind_place].numpy().squeeze()\n",
    "                        if self.is_3d:\n",
    "                            next_frame = df.loc[next_frame_ind, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "                            curr_node = df.loc[i, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "                        else:\n",
    "                            next_frame = df.loc[next_frame_ind, [\"centroid_row\", \"centroid_col\"]].values\n",
    "                            curr_node = df.loc[i, [\"centroid_row\", \"centroid_col\"]].values\n",
    "\n",
    "                        distance = ((next_frame - curr_node) ** 2).sum(axis=-1)\n",
    "                        nearest_cell = np.argmin(distance, axis=-1)\n",
    "                        # add to the array\n",
    "                        next_node_ind = next_frame_ind[nearest_cell]\n",
    "\n",
    "                    elif ind_place.shape[-1] == 1:  # one node in the next frame is connected to current node\n",
    "                        next_node_ind = connected_indices[1, ind_place[0]]\n",
    "                    else:  # no node in the next frame is connected to current node -\n",
    "                        # in this case we end the trajectory\n",
    "                        next_node_ind = -1\n",
    "\n",
    "                else:\n",
    "                    # we dont find the current node in the edge indices matrix - meaning we dont have a connection\n",
    "                    # for the node - in this case we end the trajectory and the cell\n",
    "                    if i == 0:\n",
    "                        self.flag_id0_terminate = True\n",
    "                    next_node_ind = -1\n",
    "\n",
    "                next_frame_indices = np.append(next_frame_indices, next_node_ind)#保存连接结果\n",
    "                # count the number of starting trajectories\n",
    "                start, all_frames_traject = self.insert_in_specific_col(all_frames_traject, frame_ind, i, next_node_ind)\n",
    "                num_starts += start\n",
    "\n",
    "                if start == 1:  # append the id of the cell to the list 添加新的细胞nodes（表示新开始的序列）\n",
    "                    cell_starts.append(i)\n",
    "\n",
    "            if num_starts > 0:  #说明有新的细胞轨迹\n",
    "                df_parents.append(self.find_parent_cell(frame_ind, all_frames_traject, df, num_starts, cell_starts))\n",
    "            all_trajectory_dict[frame_ind] = {'from': nodes_indices, 'to': next_frame_indices}\n",
    "\n",
    "        all_frames_traject = all_frames_traject.astype(int)\n",
    "\n",
    "        # create csv contains all the relevant information for the res_track.txt\n",
    "        df_parents_all = pd.concat(df_parents, axis=0).reset_index(drop=True)\n",
    "        df_track_res, trajectory_same_label = self.set_all_info(df_parents_all, all_frames_traject)\n",
    "\n",
    "        # convert csv to res_track.txt and res_track_real.txt\n",
    "        str_track = self.df2str(df_track_res)\n",
    "\n",
    "        # convert all_frames_traject to csv\n",
    "        df_trajectory = pd.DataFrame(all_frames_traject)\n",
    "\n",
    "\n",
    "        self.all_frames_traject = all_frames_traject\n",
    "        self.trajectory_same_label = trajectory_same_label\n",
    "        self.df_trajectory = df_trajectory\n",
    "        self.df_track = df_track_res\n",
    "        self.file_str = str_track\n",
    "\n",
    "        return all_frames_traject, trajectory_same_label, \\\n",
    "               df_trajectory,  \\\n",
    "               str_track\n",
    "\n",
    "    def get_pred(self, idx):\n",
    "        pred = None\n",
    "        if len(self.results):\n",
    "            im_path = self.results[idx]\n",
    "            pred = io.imread(im_path)\n",
    "            if self.is_3d and len(pred.shape) != 3:\n",
    "                pred = np.stack(imageio.mimread(im_path))\n",
    "                assert len(pred.shape) == 3, f\"Expected 3d dimiension! but {pred.shape}\"\n",
    "        return pred\n",
    "\n",
    "    def create_save_dir(self):\n",
    "        num_seq = self.dir_result.split('/')[-1][:2]\n",
    "        save_tra_dir = osp.join(self.dir_result, f\"../{num_seq}_RES\")\n",
    "        self.save_tra_dir =save_tra_dir\n",
    "        os.makedirs(self.save_tra_dir, exist_ok=True)\n",
    "\n",
    "    def save_new_pred(self, new_pred, idx):\n",
    "        idx_str = \"%03d\" % idx\n",
    "        file_name = f\"mask{idx_str}.tif\"\n",
    "        full_dir = osp.join(self.save_tra_dir, file_name)\n",
    "        io.imsave(full_dir, new_pred.astype(np.uint16))\n",
    "\n",
    "    def check_ids_consistent(self, frame_ind, pred_ids, curr_ids):\n",
    "\n",
    "        predID_not_in_currID = [x for x in pred_ids if x not in curr_ids]\n",
    "        currID_not_in_predID = [x for x in curr_ids if x not in pred_ids]\n",
    "        flag1 = len(predID_not_in_currID) == 1 and predID_not_in_currID[0] == 0\n",
    "        flag2 = len(currID_not_in_predID) == 0\n",
    "        if not flag2:\n",
    "            # print('pred_ids', pred_ids)\n",
    "            # print('curr_ids:', curr_ids)\n",
    "            print('currID_not_in_predID', currID_not_in_predID)\n",
    "        if not flag1:\n",
    "            str_print = f\"Frame {frame_ind}: Find segmented cell {predID_not_in_currID} without assigned labels\"\n",
    "            warnings.warn(str_print)\n",
    "            #change\n",
    "        # assert flag2, f\"Frame {frame_ind}: Find assigned labels {currID_not_in_predID} \" \\\n",
    "        #               f\"which are not appears in the final saved results\"\n",
    "        flag1 = 0\n",
    "        flag2 = 0\n",
    "\n",
    "        return flag1, predID_not_in_currID\n",
    "\n",
    "    def fix_inconsistent(self, pred_prob_ids, pred):\n",
    "        for id in pred_prob_ids:\n",
    "            if id == 0:\n",
    "                continue\n",
    "            pred[pred == id] = 0\n",
    "        return pred\n",
    "\n",
    "    def fill_mask_labels(self, debug=False):\n",
    "        self.create_save_dir()\n",
    "        all_frames_traject, trajectory_same_label = self.all_frames_traject, self.trajectory_same_label\n",
    "        df = self.df_preds\n",
    "        n_rows, n_cols = all_frames_traject.shape\n",
    "        self.flag_id0_terminate = True\n",
    "        #change\n",
    "\n",
    "        count_diff_vals = 0\n",
    "        for idx in range(n_rows):\n",
    "            pred = self.get_pred(idx)#得到相应帧数的图片\n",
    "            pred_copy = pred.copy()\n",
    "            curr_row = all_frames_traject[idx, :]#得到当前行\n",
    "            mask_id = np.bitwise_and(curr_row != -1, curr_row != -2)#选取不为空的元素位置\n",
    "            graph_ids = curr_row[mask_id]#得到mask值（all_frames_traject）\n",
    "            graph_true_ids = trajectory_same_label[idx, mask_id]#same_id里面得到（即轨迹的结束ID）\n",
    "            mask_where = np.ones_like(pred)#设置0和1的图像（保存位置\n",
    "            frame_ids = []\n",
    "            for id, true_id in zip(graph_ids, graph_true_ids):\n",
    "                #id mask 的唯一标识\n",
    "                #true_id 要修改的值\n",
    "                flag_id0 = true_id == 0\n",
    "                if flag_id0:    # edge case when the cell with id=0 terminate after one frame\n",
    "                    if self.flag_id0_terminate:\n",
    "                        new_id = trajectory_same_label.max() + 1\n",
    "                        self.df_track.child_id[self.df_track.child_id == 0] = new_id#修改trueID=0为newID\n",
    "                        self.file_str = self.df2str(self.df_track)\n",
    "                    else:\n",
    "                        assert False, \"Problem!\"\n",
    "                if self.is_3d:\n",
    "                    cell_center = df.loc[id, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values.astype(int)\n",
    "                    depth_center, row_center, col_center = cell_center[0], cell_center[1], cell_center[2]\n",
    "                    if self.center_coord:\n",
    "                        n_depth_img, n_row_img, n_col_img = pred.shape\n",
    "                        depth_center += n_depth_img // 2\n",
    "                        row_center += n_row_img // 2\n",
    "                        col_center += n_col_img // 2\n",
    "\n",
    "                    val = pred[depth_center, row_center, col_center]\n",
    "                    if 'seg_label' in df.columns:\n",
    "                        v_old = val\n",
    "                        val = df.loc[id, \"seg_label\"]\n",
    "                        count_diff_vals += 1 if v_old != val else 0\n",
    "\n",
    "                    if val == 0:\n",
    "                        if np.any(pred[depth_center-3:depth_center+3, row_center-3:row_center+3, col_center-3:col_center+3] != 0):\n",
    "                            area = pred[depth_center-3:depth_center+3, row_center-3:row_center+3, col_center-3:col_center+3]\n",
    "                            unique_labels, counts = np.unique(area, return_counts=True)\n",
    "                            mask = unique_labels != 0\n",
    "                            unique_labels = unique_labels[mask]\n",
    "                            counts = counts[mask]\n",
    "                            val = unique_labels[np.argmax(counts)]\n",
    "                        else:\n",
    "                            print(\"Problem! The provided center coordinates value is zero, should be labeled with other value\")\n",
    "                            print(df.loc[id, [\"seg_label\", \"frame_num\",  \"centroid_depth\", \"centroid_row\", \"centroid_col\", \"min_depth_bb\",\n",
    "                                              \"min_row_bb\", \"min_col_bb\", \"max_depth_bb\", \"max_row_bb\", \"max_col_bb\"]].astype(int))\n",
    "                            print()\n",
    "                            continue\n",
    "                else:\n",
    "                    cell_center = df.loc[id, [\"centroid_row\", \"centroid_col\"]].values.astype(int)#通过df找到中心位置\n",
    "                    row_center, col_center = cell_center[0], cell_center[1]\n",
    "                    if self.center_coord:\n",
    "                        n_row_img, n_col_img = pred.shape\n",
    "                        row_center += n_row_img // 2\n",
    "                        col_center += n_col_img // 2\n",
    "\n",
    "                    val = pred[row_center, col_center]\n",
    "                    if 'seg_label' in df.columns:\n",
    "                        v_old = val\n",
    "                        val = df.loc[id, \"seg_label\"]\n",
    "                        count_diff_vals += 1 if v_old != val else 0\n",
    "\n",
    "                    if val == 0:\n",
    "                        print('val = 0')\n",
    "                        if np.any(pred[row_center-3:row_center+3, col_center-3:col_center+3] != 0):\n",
    "                            area = pred[row_center-3:row_center+3, col_center-3:col_center+3]\n",
    "                            unique_labels, counts = np.unique(area, return_counts=True)\n",
    "                            mask = unique_labels != 0\n",
    "                            unique_labels = unique_labels[mask]\n",
    "                            counts = counts[mask]\n",
    "                            val = unique_labels[np.argmax(counts)]\n",
    "                        else:\n",
    "                            print(\n",
    "                                \"Problem! The provided center coordinates value is zero, should be labeled with other value\")\n",
    "                            print(df.loc[id, [\"seg_label\", \"frame_num\", \"centroid_row\", \"centroid_col\",\n",
    "                                              \"min_row_bb\", \"min_col_bb\", \"max_row_bb\", \"max_col_bb\"]].astype(int))\n",
    "                            print()\n",
    "                            continue\n",
    "                        #这段代码检查 val 是否等于 0，如果是，则说明当前像素点的预测值为 0。在这种情况下，代码尝试找到周围 3x3 区域内非零的像素值，并选择其中最常出现的像素值作为新的 val。\n",
    "\n",
    "                assert val != 0, \"Problem! The provided center coordinates value is zero, \" \\\n",
    "                                 \"should be labeled with other value\"\n",
    "                if flag_id0:\n",
    "                    true_id = new_id\n",
    "                mask_val = (pred_copy == val).copy()\n",
    "                mask_curr = np.logical_and(mask_val, mask_where)\n",
    "                pred_copy[mask_curr] = true_id\n",
    "                # if not np.any(mask_curr):\n",
    "                #     print('empty1')\n",
    "                # if idx == 4 :\n",
    "                #     plt.subplot(2,2,3)\n",
    "                #     plt.imshow(pred_copy)\n",
    "                #     if true_id == 113:\n",
    "                #         if not np.any(mask_curr):\n",
    "                #             print('empty2')\n",
    "                #         plt.subplot(2,2,1)\n",
    "                #         plt.imshow(pred_copy)\n",
    "                #         plt.subplot(2,2,2)\n",
    "                #         plt.imshow(mask_curr)\n",
    "                #         # plt.show()\n",
    "\n",
    "                mask_where = np.logical_and(np.logical_not(mask_val), mask_where)\n",
    "\n",
    "                frame_ids.append(true_id)\n",
    "\n",
    "            isOK, predID_not_in_currID = self.check_ids_consistent(idx, np.unique(pred_copy), frame_ids)\n",
    "            if not debug:\n",
    "                if not isOK:\n",
    "                    pred_copy = self.fix_inconsistent(predID_not_in_currID, pred_copy)\n",
    "                self.save_new_pred(pred_copy, idx)\n",
    "        print(f\"Number of different vals: {count_diff_vals}\")\n",
    "        self.save_txt(self.file_str, self.save_tra_dir, 'res_track.txt')\n",
    "\n",
    "\n",
    "modality = '2D'\n",
    "path_inference_output = '/data/sunrui/celldata/r03c06f04ch1/01_RES_inference'\n",
    "path_Seg_result = '/data/sunrui/celldata/r03c06f04ch1/01_GT/SEG/'\n",
    "is_3d = '3d' in modality.lower()\n",
    "directed = True\n",
    "merge_operation = 'AND'\n",
    "pp = Postprocess(is_3d=is_3d,\n",
    "                    type_masks='tif', merge_operation=merge_operation,\n",
    "                    decision_threshold=0.5,\n",
    "                    path_inference_output=path_inference_output, center_coord=False,\n",
    "                    directed=directed,\n",
    "                    path_seg_result=path_Seg_result)\n",
    "\n",
    "# all_frames_traject, trajectory_same_label, df_trajectory, str_track = pp.create_trajectory()\n",
    "# pp.fill_mask_labels(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,  ..., 16137, 16139, 16146],\n",
      "        [   53,    55,    54,  ..., 16167, 16154, 16171]])\n"
     ]
    }
   ],
   "source": [
    "all_frames_traject, trajectory_same_label, df_trajectory, str_track = pp.create_trajectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     1,     2, ...,    -2,    -2,    -2],\n",
       "       [    0,     1,     2, ...,    -2,    -2,    -2],\n",
       "       [    0,     1,    -1, ...,    -2,    -2,    -2],\n",
       "       ...,\n",
       "       [14386, 14387, 15503, ...,    -2,    -2,    -2],\n",
       "       [14386, 14387, 15503, ...,    -2,    -2,    -2],\n",
       "       [14386, 14387, 15503, ...,    -2,    -2,    -2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory_same_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     1,     2, ...,    -2,    -2,    -2],\n",
       "       [   53,    55,    54, ...,    -2,    -2,    -2],\n",
       "       [  110,   109,    -1, ...,    -2,    -2,    -2],\n",
       "       ...,\n",
       "       [16088, 16082, 16101, ...,    -2,    -2,    -2],\n",
       "       [16124, 16118, 16139, ...,    -2,    -2,    -2],\n",
       "       [16158, 16151, 16154, ...,    -2,    -2,    -2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_frames_traject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>-1</td>\n",
       "      <td>111</td>\n",
       "      <td>159</td>\n",
       "      <td>114</td>\n",
       "      <td>112</td>\n",
       "      <td>119</td>\n",
       "      <td>115</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167</td>\n",
       "      <td>166</td>\n",
       "      <td>-2</td>\n",
       "      <td>168</td>\n",
       "      <td>213</td>\n",
       "      <td>170</td>\n",
       "      <td>171</td>\n",
       "      <td>180</td>\n",
       "      <td>169</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>224</td>\n",
       "      <td>223</td>\n",
       "      <td>270</td>\n",
       "      <td>222</td>\n",
       "      <td>262</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>228</td>\n",
       "      <td>226</td>\n",
       "      <td>241</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>16028</td>\n",
       "      <td>16023</td>\n",
       "      <td>16026</td>\n",
       "      <td>16020</td>\n",
       "      <td>16028</td>\n",
       "      <td>16028</td>\n",
       "      <td>16028</td>\n",
       "      <td>16039</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>16054</td>\n",
       "      <td>16047</td>\n",
       "      <td>16052</td>\n",
       "      <td>16059</td>\n",
       "      <td>16054</td>\n",
       "      <td>16054</td>\n",
       "      <td>16054</td>\n",
       "      <td>16069</td>\n",
       "      <td>16049</td>\n",
       "      <td>16051</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>16088</td>\n",
       "      <td>16082</td>\n",
       "      <td>16101</td>\n",
       "      <td>16106</td>\n",
       "      <td>16088</td>\n",
       "      <td>16088</td>\n",
       "      <td>16088</td>\n",
       "      <td>16103</td>\n",
       "      <td>16086</td>\n",
       "      <td>16092</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>16124</td>\n",
       "      <td>16118</td>\n",
       "      <td>16139</td>\n",
       "      <td>16138</td>\n",
       "      <td>16124</td>\n",
       "      <td>16124</td>\n",
       "      <td>16124</td>\n",
       "      <td>16135</td>\n",
       "      <td>16125</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>16158</td>\n",
       "      <td>16151</td>\n",
       "      <td>16154</td>\n",
       "      <td>-1</td>\n",
       "      <td>16158</td>\n",
       "      <td>16158</td>\n",
       "      <td>16158</td>\n",
       "      <td>16166</td>\n",
       "      <td>-1</td>\n",
       "      <td>16150</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9   \\\n",
       "0        0      1      2      3      4      5      6      7      8      9   \n",
       "1       53     55     54     56     57     59     60     58     62     64   \n",
       "2      110    109     -1    111    159    114    112    119    115    121   \n",
       "3      167    166     -2    168    213    170    171    180    169    184   \n",
       "4      224    223    270    222    262    227    229    228    226    241   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "324  16028  16023  16026  16020  16028  16028  16028  16039     -1     -1   \n",
       "325  16054  16047  16052  16059  16054  16054  16054  16069  16049  16051   \n",
       "326  16088  16082  16101  16106  16088  16088  16088  16103  16086  16092   \n",
       "327  16124  16118  16139  16138  16124  16124  16124  16135  16125     -1   \n",
       "328  16158  16151  16154     -1  16158  16158  16158  16166     -1  16150   \n",
       "\n",
       "     ...  80  81  82  83  84  85  86  87  88  89  \n",
       "0    ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "1    ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "2    ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "3    ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "4    ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "324  ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "325  ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "326  ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "327  ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "328  ...  -2  -2  -2  -2  -2  -2  -2  -2  -2  -2  \n",
       "\n",
       "[329 rows x 90 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 0 36 0\\n1 0 151 0\\n2 0 1 0\\n3 0 227 0\\n4 0 151 0\\n5 0 187 0\\n6 0 151 0\\n7 0 18 0\\n8 0 207 0\\n9 0 20 0\\n10 0 15 0\\n11 0 141 0\\n12 0 26 0\\n13 0 139 0\\n14 0 226 0\\n15 0 151 0\\n16 0 69 0\\n17 0 10 0\\n18 0 88 0\\n19 0 103 0\\n20 0 151 0\\n21 0 151 0\\n22 0 6 0\\n23 0 56 0\\n24 0 151 0\\n25 0 205 0\\n26 0 151 0\\n27 0 151 0\\n28 0 151 0\\n29 0 151 0\\n30 0 328 0\\n31 0 151 0\\n32 0 10 0\\n33 0 151 0\\n34 0 111 0\\n35 0 151 0\\n36 0 88 0\\n37 0 37 0\\n38 0 151 0\\n39 0 25 0\\n40 0 76 0\\n41 0 10 0\\n42 0 10 0\\n43 0 151 0\\n44 0 10 0\\n45 0 6 0\\n46 0 130 0\\n47 0 151 0\\n48 0 6 0\\n49 0 3 0\\n50 0 10 0\\n51 0 103 0\\n52 0 10 0\\n91 1 1 0\\n107 1 7 0\\n108 1 10 0\\n113 2 151 54\\n138 2 2 54\\n162 2 151 54\\n270 4 6 214\\n306 5 6 0\\n327 5 39 0\\n359 6 151 0\\n377 6 6 0\\n445 8 151 441\\n464 8 13 441\\n481 8 10 441\\n489 8 9 441\\n498 8 10 441\\n553 9 9 0\\n555 9 18 0\\n612 11 16 594\\n658 11 11 604\\n659 11 13 604\\n672 12 20 658\\n700 12 149 658\\n701 12 12 658\\n702 12 151 658\\n704 12 151 658\\n708 12 130 658\\n712 12 77 658\\n716 12 77 658\\n770 13 13 701\\n850 15 151 0\\n867 15 151 0\\n878 15 16 0\\n899 16 28 827\\n1094 19 19 1016\\n1151 21 22 1117\\n1214 22 23 0\\n1283 23 151 1202\\n1375 25 40 0\\n1390 25 151 0\\n1399 25 27 0\\n1403 25 25 0\\n1514 28 30 1499\\n1523 28 30 1499\\n1589 29 151 1525\\n1601 29 67 1525\\n1661 31 151 1616\\n1705 31 151 1609\\n1707 32 151 0\\n1738 32 151 0\\n1758 32 32 0\\n1836 34 76 0\\n1903 35 151 0\\n1964 36 70 0\\n2135 40 91 2112\\n2233 42 98 0\\n2288 43 98 0\\n2320 43 43 0\\n2423 45 47 0\\n2424 45 49 0\\n2535 47 47 0\\n2553 48 103 2524\\n2589 49 49 0\\n2640 49 52 0\\n2647 50 51 2589\\n2651 50 51 2589\\n2799 52 76 2720\\n2804 52 151 2701\\n2807 52 55 2720\\n2863 53 54 2801\\n2914 54 54 0\\n3021 56 60 2975\\n3084 57 58 2978\\n3303 61 111 3249\\n3355 62 63 0\\n3357 62 151 0\\n3408 63 68 0\\n3412 63 63 0\\n3505 65 151 0\\n3528 65 65 0\\n3539 66 67 3528\\n3543 66 67 3528\\n3587 66 66 3528\\n3620 67 111 3587\\n3650 67 67 3587\\n3676 68 151 3610\\n3704 68 69 3640\\n3708 68 151 3610\\n3765 69 69 3691\\n3813 70 76 3761\\n3823 70 151 3711\\n3868 71 74 3822\\n3875 71 73 3822\\n3880 71 74 3822\\n3932 72 151 0\\n4052 74 151 3989\\n4158 76 76 0\\n4161 76 76 0\\n4234 78 78 4213\\n4236 78 103 4213\\n4254 78 130 4213\\n4264 78 103 4213\\n4265 78 78 4213\\n4266 78 78 4213\\n4267 78 78 4213\\n4317 79 151 4265\\n4323 79 79 4266\\n4376 80 81 4323\\n4378 81 82 0\\n4402 81 81 0\\n4425 81 103 0\\n4484 82 151 4402\\n4485 82 83 4432\\n4537 83 86 4434\\n4544 84 84 4540\\n4545 84 88 4540\\n4548 84 87 4540\\n4568 84 85 4540\\n4650 85 111 4544\\n4711 86 86 4627\\n4714 86 101 4627\\n4721 87 111 4711\\n4765 87 103 4704\\n4770 87 88 4711\\n4795 88 151 4719\\n4804 88 88 4719\\n4824 88 151 4719\\n4827 88 88 4719\\n4854 89 90 4790\\n4883 89 152 4790\\n4997 91 91 4906\\n5103 93 122 0\\n5159 95 115 0\\n5363 98 130 0\\n5446 100 103 0\\n5473 100 101 0\\n5547 101 101 0\\n5550 102 151 5527\\n5552 102 104 5527\\n5674 104 104 5624\\n5708 104 104 5631\\n5718 105 144 5665\\n5722 105 130 5708\\n5726 105 151 5674\\n5738 105 151 5665\\n5743 105 119 5708\\n5753 105 144 5665\\n5755 105 151 5665\\n5756 105 151 5665\\n5762 105 151 5708\\n5764 105 151 5674\\n5813 106 151 0\\n5873 107 108 0\\n5928 108 151 0\\n5982 109 130 5930\\n6157 112 112 6106\\n6198 113 119 6157\\n6218 113 117 6157\\n6316 115 117 0\\n6325 115 115 0\\n6386 116 145 6325\\n6437 117 130 0\\n6444 118 118 6429\\n6500 119 120 6444\\n6542 119 121 6444\\n6558 120 120 6526\\n6639 121 121 6558\\n6667 121 151 6558\\n6672 122 122 6651\\n6715 122 130 6651\\n6717 122 151 6651\\n6725 123 123 6672\\n6826 124 130 6725\\n6830 124 124 6725\\n6860 125 126 6830\\n6878 125 151 6830\\n6880 125 125 6830\\n6941 126 127 6880\\n6996 127 130 6918\\n7030 128 128 6999\\n7042 128 128 6999\\n7057 128 128 6999\\n7061 128 130 6999\\n7062 129 135 7042\\n7113 129 130 7042\\n7148 130 130 0\\n7172 130 151 0\\n7180 131 131 7161\\n7187 131 131 7171\\n7203 131 131 7173\\n7222 131 131 7171\\n7229 131 151 7179\\n7237 132 132 7203\\n7250 132 139 7222\\n7252 132 139 7222\\n7268 132 151 7180\\n7269 132 138 7222\\n7279 132 138 7222\\n7280 132 151 7222\\n7283 132 151 7180\\n7284 132 135 7222\\n7288 132 133 7222\\n7458 135 137 0\\n7466 135 135 0\\n7528 137 143 0\\n7590 138 138 7569\\n7721 140 149 7658\\n7729 140 151 7644\\n7733 140 143 7658\\n7734 140 151 7658\\n7735 140 141 7658\\n7741 140 143 7658\\n7748 140 151 7658\\n7800 141 151 0\\n7806 141 151 0\\n7807 141 141 0\\n7826 142 142 7788\\n7832 142 151 7807\\n7869 143 145 7826\\n7914 143 151 7826\\n7916 143 151 7826\\n7974 144 144 7913\\n8006 145 146 7974\\n8024 145 151 7974\\n8075 146 146 7981\\n8078 146 151 8034\\n8140 147 148 8075\\n8177 148 151 0\\n8181 148 148 0\\n8212 149 151 8197\\n8255 149 151 8181\\n8258 150 151 8220\\n8280 150 151 8250\\n8298 150 151 8220\\n8309 150 150 8250\\n8322 151 151 8309\\n8380 153 154 8379\\n8382 153 219 8379\\n8383 153 157 8379\\n8384 153 207 8379\\n8386 153 238 8379\\n8387 153 235 8379\\n8388 153 231 8379\\n8390 153 306 8379\\n8392 153 154 8379\\n8393 153 218 8379\\n8395 153 298 8379\\n8396 153 154 8379\\n8397 153 276 8379\\n8398 153 245 8379\\n8400 153 263 8379\\n8401 153 327 8379\\n8402 153 241 8379\\n8403 153 285 8379\\n8404 153 178 8379\\n8405 153 293 8379\\n8406 153 157 8379\\n8407 153 229 8379\\n8408 153 194 8379\\n8409 153 245 8379\\n8410 153 213 8379\\n8411 153 294 8379\\n8412 153 216 8379\\n8413 153 181 8379\\n8414 153 154 8379\\n8415 153 181 8379\\n8416 153 239 8379\\n8417 153 154 8379\\n8418 153 187 8379\\n8419 153 323 8379\\n8420 153 328 8379\\n8421 153 181 8379\\n8422 153 276 8379\\n8423 153 181 8379\\n8424 153 224 8379\\n8425 153 157 8379\\n8426 153 154 8379\\n8427 153 245 8379\\n8428 153 216 8379\\n8429 153 171 8379\\n8430 153 157 8379\\n8431 153 245 8379\\n8432 153 328 8379\\n8433 153 154 8379\\n8434 153 154 8379\\n8435 153 157 8379\\n8436 153 181 8379\\n8437 153 154 8379\\n8480 154 157 0\\n8486 154 166 0\\n8498 155 155 8438\\n8546 156 268 8498\\n8558 156 157 8498\\n8564 156 181 8498\\n8571 156 181 8498\\n8576 156 245 8498\\n8580 156 181 8498\\n8588 156 157 8498\\n8589 156 157 8498\\n8590 156 157 8498\\n8591 156 245 8498\\n8593 156 216 8498\\n8599 156 166 8498\\n8600 156 216 8498\\n8601 156 157 8498\\n8603 156 157 8498\\n8604 156 157 8498\\n8631 157 187 0\\n8633 157 157 0\\n8662 157 157 0\\n8663 157 161 0\\n8669 158 158 8668\\n8673 158 158 8662\\n8715 158 171 8633\\n8720 159 160 8673\\n8722 159 187 8673\\n8739 159 169 8673\\n8744 159 187 8673\\n8746 159 181 8673\\n8753 159 245 8669\\n8756 159 181 8673\\n8761 159 163 8673\\n8765 159 181 8673\\n8766 159 193 8669\\n8768 159 183 8673\\n8769 159 328 8673\\n8770 159 216 8673\\n8779 159 161 8673\\n8780 159 216 8673\\n8781 159 193 8669\\n8782 159 193 8669\\n8783 159 161 8673\\n8786 160 161 0\\n8831 160 183 0\\n8912 162 162 8850\\n8937 162 162 8850\\n8960 162 268 8850\\n8968 162 183 8905\\n8976 163 163 8912\\n9030 163 175 8912\\n9033 163 163 8937\\n9036 163 163 8912\\n9040 164 169 8976\\n9092 164 169 8976\\n9097 164 179 8976\\n9160 166 172 0\\n9217 166 167 0\\n9320 168 168 9280\\n9324 168 168 9280\\n9394 169 169 9320\\n9408 170 170 9356\\n9412 170 170 9351\\n9464 170 193 9394\\n9471 171 171 9412\\n9481 171 176 9408\\n9500 171 183 9408\\n9523 171 171 9412\\n9524 171 203 9412\\n9574 172 183 9523\\n9603 173 173 9526\\n9637 173 175 9526\\n9643 173 181 9526\\n9644 174 228 9603\\n9746 175 176 0\\n9812 176 181 9750\\n9823 177 177 9763\\n9869 177 183 9763\\n9877 177 183 9810\\n9892 178 181 9823\\n9925 178 181 9823\\n9933 178 178 9823\\n9999 179 179 9933\\n10051 180 181 9982\\n10053 180 180 9982\\n10110 181 181 10053\\n10117 182 182 10068\\n10118 182 182 10082\\n10161 183 194 10117\\n10166 183 194 10117\\n10179 183 189 10117\\n10180 183 245 10117\\n10185 183 295 10118\\n10190 183 220 10117\\n10191 183 220 10117\\n10194 183 295 10118\\n10195 183 216 10118\\n10198 183 245 10117\\n10202 183 194 10117\\n10204 183 213 10118\\n10207 183 194 10118\\n10209 183 183 10117\\n10211 183 187 10117\\n10212 183 186 10117\\n10213 183 193 10117\\n10267 185 185 0\\n10316 185 185 0\\n10320 185 194 0\\n10321 185 186 0\\n10323 185 187 0\\n10325 185 193 0\\n10374 186 186 10267\\n10455 188 193 10434\\n10458 188 240 10423\\n10486 188 194 10423\\n10487 188 188 10423\\n10489 188 188 10423\\n10541 189 189 10487\\n10543 189 245 10489\\n10544 189 191 10487\\n10545 189 189 10487\\n10546 189 189 10489\\n10601 191 193 0\\n10620 191 194 0\\n10622 191 194 0\\n10648 191 194 0\\n10649 191 245 0\\n10651 191 191 0\\n10653 191 193 0\\n10654 191 194 0\\n10665 192 192 10643\\n10709 192 194 10651\\n10748 193 193 10665\\n10766 193 193 10665\\n10823 194 194 10748\\n10825 194 199 10766\\n10868 195 195 10819\\n10869 195 195 10798\\n10872 196 212 10868\\n10890 196 210 10868\\n10893 196 304 10869\\n10895 196 228 10869\\n10900 196 196 10868\\n10912 196 220 10868\\n10913 196 220 10868\\n10917 196 245 10869\\n10918 196 210 10868\\n10919 196 197 10868\\n10922 196 198 10869\\n10923 196 197 10868\\n10964 197 200 10900\\n10969 197 268 10900\\n10979 197 203 10900\\n10980 197 197 10900\\n11030 198 203 10974\\n11085 199 199 11035\\n11088 199 200 11035\\n11089 199 199 11035\\n11090 199 276 11035\\n11193 201 210 11143\\n11196 201 208 11140\\n11197 201 216 11143\\n11248 202 202 0\\n11250 202 210 0\\n11265 203 203 11248\\n11318 204 207 11302\\n11362 204 205 11304\\n11409 205 205 0\\n11413 205 207 0\\n11467 206 208 11377\\n11473 207 207 0\\n11520 207 245 0\\n11532 208 208 11479\\n11542 208 225 11477\\n11576 208 208 11479\\n11623 209 209 11576\\n11624 209 222 11532\\n11636 210 210 11623\\n11678 210 213 11623\\n11727 211 212 11657\\n11746 212 218 0\\n11749 212 212 0\\n11763 212 212 0\\n11777 212 218 0\\n11785 213 213 11749\\n11788 213 216 11749\\n11827 213 222 11763\\n11837 214 217 11785\\n11839 214 214 11785\\n11843 214 214 11786\\n11861 214 223 11785\\n11873 214 219 11785\\n11928 215 218 11839\\n11932 215 217 11839\\n11987 216 265 0\\n12015 217 217 11976\\n12050 218 218 11991\\n12084 218 218 11991\\n12086 219 219 12050\\n12120 219 220 12050\\n12128 219 223 12050\\n12167 220 222 12121\\n12170 220 220 12088\\n12172 220 220 12088\\n12175 220 220 12086\\n12176 220 224 12086\\n12177 221 221 12172\\n12199 221 222 12172\\n12215 221 223 12155\\n12223 222 222 12177\\n12224 222 223 12177\\n12236 222 274 12177\\n12252 222 222 12177\\n12259 222 222 12177\\n12281 223 223 12243\\n12308 223 223 12257\\n12313 224 224 12288\\n12316 224 328 12308\\n12328 224 275 12272\\n12335 224 241 12272\\n12343 224 224 12288\\n12349 224 275 12272\\n12354 224 224 12281\\n12371 225 227 12333\\n12373 225 230 12313\\n12390 225 234 12313\\n12394 225 227 12354\\n12396 225 227 12333\\n12401 225 226 12313\\n12402 225 227 12333\\n12405 226 226 12400\\n12450 227 227 12447\\n12480 227 234 12405\\n12489 227 245 12447\\n12491 227 227 12432\\n12530 228 266 12491\\n12556 229 230 12509\\n12568 229 229 12505\\n12570 229 229 12505\\n12572 229 229 12505\\n12573 229 239 12505\\n12576 230 245 12568\\n12589 230 250 12542\\n12598 230 231 12568\\n12601 230 234 12568\\n12614 230 230 12568\\n12615 230 230 12542\\n12617 230 247 12568\\n12618 231 231 12577\\n12624 231 304 12604\\n12657 231 232 12604\\n12663 232 275 12640\\n12665 232 232 12631\\n12684 232 234 12640\\n12695 232 234 12640\\n12699 232 234 12640\\n12700 232 232 12640\\n12705 233 236 12700\\n12710 233 234 12700\\n12747 233 233 12703\\n12754 234 234 12747\\n12763 234 234 12747\\n12793 234 240 12747\\n12842 236 269 12817\\n12865 236 253 12817\\n12870 236 237 12817\\n12871 236 236 12817\\n12874 236 236 12817\\n12889 237 237 12871\\n12895 237 237 12871\\n12923 238 239 12913\\n12949 238 239 12913\\n12956 238 328 12889\\n12967 239 245 12935\\n12989 239 241 12935\\n12998 239 239 12935\\n13001 239 241 12935\\n13005 239 239 12935\\n13029 240 253 12982\\n13040 240 247 12982\\n13045 240 240 12961\\n13046 241 243 13045\\n13047 241 241 13022\\n13060 241 264 13022\\n13076 241 241 13044\\n13080 241 241 13022\\n13084 241 328 13044\\n13086 241 241 13045\\n13090 241 242 13045\\n13091 241 241 13044\\n13097 242 242 13056\\n13123 242 243 13052\\n13127 242 242 13080\\n13130 242 246 13076\\n13143 243 264 13127\\n13156 243 253 13127\\n13170 244 245 13164\\n13172 244 245 13164\\n13197 244 245 13164\\n13205 244 244 13132\\n13206 244 244 13132\\n13209 244 244 13132\\n13211 245 246 13205\\n13217 245 245 13206\\n13251 245 276 13206\\n13261 246 246 13247\\n13264 246 246 13247\\n13276 246 246 13247\\n13279 246 246 13247\\n13286 246 246 13247\\n13288 246 246 13215\\n13291 246 246 13247\\n13292 246 246 13233\\n13293 247 247 13261\\n13296 247 253 13288\\n13299 247 328 13288\\n13308 247 259 13264\\n13319 247 302 13286\\n13327 247 253 13291\\n13330 247 248 13264\\n13331 248 252 13293\\n13336 248 253 13325\\n13360 248 251 13293\\n13369 248 251 13293\\n13370 248 248 13293\\n13375 249 249 13370\\n13376 249 253 13367\\n13377 249 253 13367\\n13409 249 249 13367\\n13447 250 251 13409\\n13451 250 253 13409\\n13452 250 253 13409\\n13453 250 260 13375\\n13458 251 253 13437\\n13501 252 252 13489\\n13506 252 252 13488\\n13529 252 253 13489\\n13564 253 253 13501\\n13565 253 253 13501\\n13568 253 253 13506\\n13572 253 253 13501\\n13574 254 254 13565\\n13575 254 254 13537\\n13576 254 254 13565\\n13607 255 258 13574\\n13626 255 258 13576\\n13637 255 258 13575\\n13638 255 258 13574\\n13639 255 255 13575\\n13641 255 259 13574\\n13643 256 257 13639\\n13676 256 257 13639\\n13679 256 256 13639\\n13695 257 257 13679\\n13705 257 257 13679\\n13713 257 257 13679\\n13715 257 257 13679\\n13720 258 258 13715\\n13721 258 328 13705\\n13754 258 258 13695\\n13756 258 258 13705\\n13757 258 258 13695\\n13759 259 260 13744\\n13789 259 259 13748\\n13810 260 264 13766\\n13825 261 261 13824\\n13828 261 261 13824\\n13846 261 261 13793\\n13849 261 261 13793\\n13851 261 261 13793\\n13859 261 261 13793\\n13860 261 261 13824\\n13861 262 262 13851\\n13864 262 262 13859\\n13892 262 263 13849\\n13893 262 267 13846\\n13899 263 263 13861\\n13913 263 269 13861\\n13914 263 266 13861\\n13915 263 264 13861\\n13926 263 263 13861\\n13928 263 269 13864\\n13930 263 263 13864\\n13932 263 275 13861\\n13933 264 266 13929\\n13934 264 266 13901\\n13938 264 264 13901\\n13939 264 264 13930\\n13961 264 264 13901\\n13978 265 267 13967\\n13989 265 266 13938\\n14004 265 267 13956\\n14008 265 265 13961\\n14046 266 328 14007\\n14051 267 280 14017\\n14084 268 273 14079\\n14108 268 268 14079\\n14132 269 280 14108\\n14139 269 269 14108\\n14141 269 274 14108\\n14144 269 269 14108\\n14145 269 328 14103\\n14165 270 275 14136\\n14203 271 275 0\\n14204 271 275 0\\n14231 272 275 0\\n14238 272 272 0\\n14240 272 273 0\\n14241 272 272 0\\n14244 272 274 0\\n14245 272 272 0\\n14255 273 275 14238\\n14272 273 302 14241\\n14288 274 274 14279\\n14303 274 274 14279\\n14325 275 275 14288\\n14337 275 279 14288\\n14340 275 280 14294\\n14353 276 277 14347\\n14355 276 278 14348\\n14377 276 277 14323\\n14378 276 277 14323\\n14380 276 276 14347\\n14386 277 328 14357\\n14387 277 328 14380\\n14389 277 306 14357\\n14399 277 302 14380\\n14401 277 302 14380\\n14409 277 282 14364\\n14411 277 306 14357\\n14412 277 302 14380\\n14413 277 302 14380\\n14415 277 302 14380\\n14417 277 299 14380\\n14441 278 306 14381\\n14451 278 328 14381\\n14452 278 306 14381\\n14456 279 288 14421\\n14457 279 279 14421\\n14482 279 283 14421\\n14486 279 279 14421\\n14491 279 279 14421\\n14511 280 284 14457\\n14516 280 284 14457\\n14520 280 301 14457\\n14533 281 287 14492\\n14545 281 281 14492\\n14553 281 282 14507\\n14556 281 281 14492\\n14558 281 281 14492\\n14568 281 328 14507\\n14595 282 282 14545\\n14600 282 282 14558\\n14603 282 282 14556\\n14606 282 282 14545\\n14607 282 315 14545\\n14633 283 283 14600\\n14634 283 299 14600\\n14641 283 302 14595\\n14645 284 285 14638\\n14650 284 285 14638\\n14669 284 306 14633\\n14677 284 285 14638\\n14678 284 288 14638\\n14682 285 328 14671\\n14702 285 286 14671\\n14711 285 287 14671\\n14719 285 285 14671\\n14725 286 290 14699\\n14750 286 302 14719\\n14754 286 286 14719\\n14757 286 328 14719\\n14787 287 288 14754\\n14790 287 288 14738\\n14792 287 288 14738\\n14795 287 287 14754\\n14810 288 301 14763\\n14811 288 291 14788\\n14827 288 302 14763\\n14828 288 288 14763\\n14865 289 289 14828\\n14866 289 292 14825\\n14887 290 290 14865\\n14904 290 302 14865\\n14935 291 292 14869\\n14938 291 301 14887\\n14949 292 328 14910\\n14954 292 292 14910\\n14966 292 299 14910\\n14972 292 293 14910\\n14988 293 293 14974\\n15010 293 293 14976\\n15022 294 294 14995\\n15025 294 306 15010\\n15029 294 306 15012\\n15042 294 299 15010\\n15046 294 306 15012\\n15049 294 306 14988\\n15054 294 302 14995\\n15059 295 300 15040\\n15060 295 306 15040\\n15061 295 297 15022\\n15083 295 297 15022\\n15089 295 300 15040\\n15093 296 296 15072\\n15097 296 296 15055\\n15114 296 306 15072\\n15119 296 296 15072\\n15127 296 302 15055\\n15133 297 298 15093\\n15161 297 297 15093\\n15166 298 298 15161\\n15174 298 299 15154\\n15175 298 304 15154\\n15186 298 302 15154\\n15199 298 306 15161\\n15210 299 300 15166\\n15226 299 306 15168\\n15229 299 306 15166\\n15232 299 306 15166\\n15234 299 299 15166\\n15239 299 306 15166\\n15244 300 327 15240\\n15266 300 306 15205\\n15271 300 300 15240\\n15274 300 302 15240\\n15283 301 328 15249\\n15284 301 301 15271\\n15287 301 302 15275\\n15304 301 302 15271\\n15305 301 306 15249\\n15308 301 306 15271\\n15313 301 301 15249\\n15314 301 301 15271\\n15319 302 302 15297\\n15322 302 302 15313\\n15325 302 302 15284\\n15335 302 302 15313\\n15339 302 302 15284\\n15350 302 302 15284\\n15351 303 303 15322\\n15357 303 328 15339\\n15377 304 304 15351\\n15382 304 306 15351\\n15383 304 305 15351\\n15387 304 306 15351\\n15388 304 304 15351\\n15391 304 304 15351\\n15392 304 306 15351\\n15396 304 306 15351\\n15400 304 306 15351\\n15401 304 306 15351\\n15406 304 304 15351\\n15409 304 305 15351\\n15410 304 315 15351\\n15413 304 305 15351\\n15414 304 306 15351\\n15415 304 327 15351\\n15443 305 305 15408\\n15449 306 307 15444\\n15454 306 312 15443\\n15473 306 306 15443\\n15503 308 328 15480\\n15508 308 328 15480\\n15509 308 321 15480\\n15511 308 309 15480\\n15516 308 328 15480\\n15518 308 328 15480\\n15519 308 316 15480\\n15520 308 321 15480\\n15521 308 308 15480\\n15523 308 328 15480\\n15524 308 308 15480\\n15528 308 316 15480\\n15529 308 328 15480\\n15533 309 321 15521\\n15538 309 316 15524\\n15557 309 314 15521\\n15558 309 316 15524\\n15569 310 316 15559\\n15574 310 327 15559\\n15578 310 310 15559\\n15590 310 310 15559\\n15592 310 328 15559\\n15598 311 312 15590\\n15605 311 312 15590\\n15617 311 312 15578\\n15619 311 312 15590\\n15624 311 316 15590\\n15637 312 316 0\\n15640 312 312 0\\n15655 312 313 0\\n15658 312 321 0\\n15677 313 323 15651\\n15680 313 313 15632\\n15693 313 316 15651\\n15694 313 321 15657\\n15701 313 316 15651\\n15702 313 328 15648\\n15722 314 323 15692\\n15757 315 316 15729\\n15761 315 315 15729\\n15764 315 316 15729\\n15791 316 317 15769\\n15792 316 316 15765\\n15831 318 320 15822\\n15833 318 320 15822\\n15835 318 320 15822\\n15838 318 320 15822\\n15843 318 328 15822\\n15849 318 320 15822\\n15853 318 320 15822\\n15855 318 320 15822\\n15856 318 320 15822\\n15857 318 320 15822\\n15858 318 320 15822\\n15884 319 320 0\\n15891 319 320 0\\n15892 319 328 0\\n15893 319 320 0\\n15894 319 320 0\\n15897 319 320 0\\n15920 320 320 0\\n15964 322 327 15953\\n15981 323 327 0\\n15989 323 323 0\\n15990 323 323 0\\n15991 323 325 0\\n16003 323 323 0\\n16005 323 327 0\\n16006 323 327 0\\n16007 323 323 0\\n16009 323 328 0\\n16010 323 323 0\\n16011 323 323 0\\n16012 323 327 0\\n16013 323 327 0\\n16014 323 323 0\\n16015 323 323 0\\n16040 324 327 15988\\n16049 325 327 0\\n16051 325 326 0\\n16053 325 326 0\\n16062 325 328 0\\n16065 325 327 0\\n16067 325 327 0\\n16072 325 327 0\\n16073 325 327 0\\n16076 325 325 0\\n16080 326 328 16076\\n16098 326 327 16076\\n16099 326 328 16076\\n16110 326 326 16057\\n16112 327 327 16085\\n16121 327 327 16110\\n16142 327 327 16110\\n16146 327 328 16110\\n16150 328 328 16132\\n16153 328 328 16121\\n16156 328 328 16112\\n16159 328 328 16121\\n16163 328 328 16123\\n16168 328 328 16123\\n16169 328 328 16145\\n16170 328 328 16112\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.fill_mask_labels(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell-tracking-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
