{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunrui/anaconda3/envs/cell-tracking-challenge/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import imageio\n",
    "\n",
    "\n",
    "class Postprocess(object):\n",
    "    def __init__(self,\n",
    "                 is_3d,\n",
    "                 type_masks,\n",
    "                 merge_operation,\n",
    "                 decision_threshold,\n",
    "                 path_inference_output,\n",
    "                 center_coord,\n",
    "                 path_seg_result,\n",
    "                 directed=True\n",
    "                 ):\n",
    "\n",
    "        file1 = os.path.join(path_inference_output, 'pytorch_geometric_data.pt')\n",
    "        file2 = os.path.join(path_inference_output, 'all_data_df.csv')\n",
    "        file3 = os.path.join(path_inference_output, 'raw_output.pt')\n",
    "\n",
    "        self.dir_result = dir_results = path_seg_result\n",
    "        self.results = []\n",
    "        if os.path.exists(dir_results):\n",
    "            self.results = [os.path.join(dir_results, fname) for fname in sorted(os.listdir(dir_results))\n",
    "                            if type_masks in fname]\n",
    "\n",
    "        self.is_3d = is_3d\n",
    "        self.center_coord = center_coord\n",
    "        self.merge_operation = merge_operation\n",
    "        self.decision_threshold = decision_threshold\n",
    "        self.directed = directed\n",
    "        self.path_inference_output = path_inference_output\n",
    "        self.cols = [\"child_id\", \"parent_id\", \"start_frame\"]\n",
    "\n",
    "        data = self._load_file(file1)\n",
    "        self.edge_index = data.edge_index\n",
    "\n",
    "        self.df_preds = self._load_file(file2)\n",
    "        self.output_pred = self._load_file(file3)\n",
    "        self.change_sec_id()\n",
    "        self.find_connected_edges()\n",
    "\n",
    "    def change_sec_id(self):\n",
    "        edge_index, df, outputs = self.edge_index, self.df_preds, self.output_pred\n",
    "        outputs_soft = torch.sigmoid(outputs)\n",
    "        outputs_hard = (outputs_soft > self.decision_threshold).int()\n",
    "        print(outputs_hard)\n",
    "\n",
    "        connected_indices = edge_index[:, outputs_hard.bool()]#取出符合要求的边缘\n",
    "        output_save_pre = outputs[outputs_hard.bool()]#取出符合要求的边缘置信度\n",
    "        print(connected_indices.shape)\n",
    "        print(output_save_pre.shape)\n",
    "\n",
    "        print(connected_indices)#change\n",
    "        print(connected_indices.shape)\n",
    "\n",
    "        label_fir = connected_indices[0,:]\n",
    "        label_sec = connected_indices[1,:]\n",
    "        label_sec_unique = np.unique(label_sec)\n",
    "\n",
    "\n",
    "\n",
    "        # 获取每个标签的行和列change_1008\n",
    "        first_positions = df.loc[label_fir, [\"centroid_row\", \"centroid_col\"]].values\n",
    "        second_positions = df.loc[label_sec, [\"centroid_row\", \"centroid_col\"]].values\n",
    "\n",
    "        # 计算距离矩阵\n",
    "        distances = ((second_positions - first_positions) ** 2).sum(axis=-1)\n",
    "        distances = np.sqrt(distances)\n",
    "\n",
    "        # 创建一个矩阵来标识需要保留的连接\n",
    "        keep_mask = np.zeros_like(distances, dtype=bool)\n",
    "\n",
    "        for label in label_sec_unique:\n",
    "            label_indices = np.where(label_sec == label)[0]\n",
    "            if len(label_indices) > 1:\n",
    "                label_distances = distances[label_indices]\n",
    "                min_distance_index = np.argmin(label_distances)\n",
    "                keep_mask[label_indices[min_distance_index]] = True\n",
    "            else:\n",
    "                keep_mask[label_indices] = True\n",
    "            \n",
    "        # 使用布尔索引删除不需要的连接\n",
    "        connected_indices = connected_indices[:, keep_mask]\n",
    "        output_save_pre = output_save_pre[keep_mask]\n",
    "\n",
    "\n",
    "\n",
    "        # for label in label_sec_unique:\n",
    "        #     label_cols = label_sec[label_sec == label]\n",
    "        #     if label_cols.shape[0] > 1:\n",
    "            \n",
    "        #         ind_place_col = np.argwhere(label_sec==label)\n",
    "            \n",
    "        #         curr_position = df.loc[label,[\"centroid_row\", \"centroid_col\"]].values   #第二行的位置\n",
    "                \n",
    "                \n",
    "        #         x = label_fir[ind_place_col].numpy().squeeze()\n",
    "        #         first_position = df.loc[x, [\"centroid_row\", \"centroid_col\"]].values     #第一行的位置\n",
    "\n",
    "        #         distance = ((curr_position - first_position) ** 2).sum(axis=-1)\n",
    "        #         nearest_cell = np.argmin(distance, axis=-1)\n",
    "        #         node_remain = x[nearest_cell]     #要保留的ID\n",
    "\n",
    "\n",
    "        #         delet_id = np.delete(x, np.where(x == node_remain))#需要改数据类型\n",
    "\n",
    "        #         for del_id in delet_id:\n",
    "        #             # 使用布尔索引删除连接\n",
    "        #             delet_mask = np.logical_and(connected_indices[0, :] == del_id, connected_indices[1, :] == label)\n",
    "        #             delete_indices = np.where(delet_mask)[0]\n",
    "        #             delete_indices_test = np.where(delet_mask)\n",
    "        #             connected_indices = np.delete(connected_indices, delete_indices, axis=1)\n",
    "        #             output_save_pre = np.delete(output_save_pre,delete_indices)\n",
    "\n",
    "        # 打印结果\n",
    "        print(\"Connected Indices (After Filtering):\")\n",
    "        print(connected_indices)\n",
    "        print(connected_indices.shape)\n",
    "        print(output_save_pre)\n",
    "        print(output_save_pre.shape)\n",
    "\n",
    "        self.output_pred = output_save_pre\n",
    "        self.edge_index = connected_indices\n",
    "\n",
    "\n",
    "    def _load_file(self, file_path):\n",
    "        print(f\"Load {file_path}\")\n",
    "        file_type = file_path.split('.')[-1]\n",
    "        if file_type == 'csv':\n",
    "            file = pd.read_csv(file_path, index_col=0)\n",
    "        if file_type == 'pt':\n",
    "            file = torch.load(file_path)\n",
    "        return file\n",
    "\n",
    "    def save_csv(self, df_file, file_name):\n",
    "        full_name = os.path.join(self.path_inference_output, f\"postprocess_data\")\n",
    "        os.makedirs(full_name, exist_ok=True)\n",
    "        full_name = os.path.join(full_name, file_name)\n",
    "        df_file.to_csv(full_name)\n",
    "\n",
    "    def save_txt(self, str_txt, output_folder, file_name):\n",
    "        full_name = os.path.join(output_folder, file_name)\n",
    "        with open(full_name, \"w\") as text_file:\n",
    "            text_file.write(str_txt)\n",
    "\n",
    "    def insert_in_specific_col(self, all_frames_traject, frame_ind, curr_node, next_node):\n",
    "        if curr_node in all_frames_traject[frame_ind, :]:\n",
    "            flag = 0\n",
    "            ind_place = np.argwhere(all_frames_traject[frame_ind, :] == curr_node)\n",
    "            if frame_ind + 1 < all_frames_traject.shape[0]:\n",
    "                all_frames_traject[frame_ind + 1, ind_place] = next_node\n",
    "        else:\n",
    "            flag = 1\n",
    "            ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -2)\n",
    "            while ind_place.size == 0:\n",
    "                new_col = -2 * np.ones((all_frames_traject.shape[0], 1), dtype=all_frames_traject.dtype)\n",
    "                all_frames_traject = np.append(all_frames_traject, new_col, axis=1)\n",
    "                ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -2)\n",
    "            ind_place = ind_place.min()\n",
    "            all_frames_traject[frame_ind, ind_place] = curr_node\n",
    "            if frame_ind + 1 < all_frames_traject.shape[0]:\n",
    "                all_frames_traject[frame_ind + 1, ind_place] = next_node\n",
    "\n",
    "        return flag, all_frames_traject\n",
    "\n",
    "    def fill_first_frame(self, cell_starts):\n",
    "        cols = [\"child_id\", \"parent_id\", \"start_frame\"]\n",
    "        df_parent = pd.DataFrame(index=range(len(list(cell_starts))), columns=cols)\n",
    "        df_parent.loc[:, [\"start_frame\", \"parent_id\"]] = 0\n",
    "        df_parent.loc[:, \"child_id\"] = cell_starts\n",
    "        return df_parent\n",
    "\n",
    "    def find_parent_cell(self, frame_ind, all_frames_traject, df, num_starts, cell_starts):\n",
    "        ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -1)\n",
    "        finish_node_ids = all_frames_traject[frame_ind - 1, ind_place].squeeze(axis=1)\n",
    "        # print(f\"frame_ind: {frame_ind}, cell_starts: {cell_starts}, cell_ends: {finish_node_ids}\")\n",
    "\n",
    "        df_parent = pd.DataFrame(index=range(len(cell_starts)), columns=self.cols)\n",
    "        df_parent.loc[:, \"start_frame\"] = frame_ind\n",
    "\n",
    "        if finish_node_ids.shape[0] != 0:\n",
    "            if self.is_3d:\n",
    "                finish_cell = df.loc[finish_node_ids, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "            else:\n",
    "                finish_cell = df.loc[finish_node_ids, [\"centroid_row\", \"centroid_col\"]].values\n",
    "            for ind, cell in enumerate(cell_starts):\n",
    "                if self.is_3d:\n",
    "                    curr_cell = df.loc[cell, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "                else:\n",
    "                    curr_cell = df.loc[cell, [\"centroid_row\", \"centroid_col\"]].values\n",
    "\n",
    "                distance = ((finish_cell - curr_cell) ** 2).sum(axis=-1)\n",
    "                nearest_cell = np.argmin(distance, axis=-1)\n",
    "                parent_cell = int(finish_node_ids[nearest_cell])\n",
    "                df_parent.loc[ind, \"child_id\"] = cell\n",
    "                df_parent.loc[ind, \"parent_id\"] = parent_cell\n",
    "        else:\n",
    "            df_parent.loc[:, \"child_id\"] = cell_starts\n",
    "            df_parent.loc[:, \"parent_id\"] = 0\n",
    "\n",
    "        return df_parent\n",
    "\n",
    "    def clean_repetition(self, df):\n",
    "        all_childs = df.child_id.values\n",
    "        unique_vals, count_vals = np.unique(all_childs, return_counts=True)\n",
    "        prob_vals = unique_vals[count_vals > 1]\n",
    "        for prob_val in prob_vals:\n",
    "            masking = df.child_id.values == prob_val\n",
    "            all_apearence = df.loc[masking, :]\n",
    "            start_frame = all_apearence.start_frame.min()\n",
    "            end_frame = all_apearence.end_frame.max()\n",
    "            df.loc[all_apearence.index[0], [\"start_frame\", \"end_frame\"]] = start_frame, end_frame\n",
    "            df = df.drop(all_apearence.index[1:])\n",
    "\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "    def set_all_info(self, df_parents_all, all_frames_traject):\n",
    "\n",
    "        iterate_childs = df_parents_all.child_id.values\n",
    "        frames_traject_same_label = all_frames_traject.copy()\n",
    "        for ind, child_ind in enumerate(iterate_childs):\n",
    "            # find the place where we store the child_ind in the trajectory matrix\n",
    "            # validate that only one place exists\n",
    "            coordinates_child = np.argwhere(all_frames_traject == child_ind)\n",
    "            n_places = coordinates_child.shape[0]\n",
    "\n",
    "            assert n_places == 1, f\"Problem! find {n_places} places which the current child appears\"\n",
    "\n",
    "            coordinates_child = coordinates_child.squeeze()\n",
    "            row, col = coordinates_child\n",
    "            s_frame = df_parents_all.loc[ind, \"start_frame\"]\n",
    "            assert row == s_frame, f\"Problem! start frame {s_frame} is not equal to row {row}\"\n",
    "\n",
    "            # take the specific col from 'row' down\n",
    "            curr_col = all_frames_traject[row:, col]\n",
    "            last_ind = np.argwhere(curr_col == -1)\n",
    "            if last_ind.size != 0:\n",
    "                last_ind = last_ind[0].squeeze()\n",
    "                curr_col = curr_col[:last_ind]\n",
    "            e_frame = row + curr_col.shape[0] - 1\n",
    "\n",
    "            #change_1123\n",
    "            # old_child_id = df_parents_all.loc[ind, \"child_id\"] #1\n",
    "            # curr_id_cp = curr_col[-1] #5\n",
    "            # df_parents_all.loc[:,df_parents_all.loc['child_id'] == curr_id_cp] #寻找parent_id为curr_id_cp的所有列，修改parent_id为old_child_id\n",
    "            \n",
    "\n",
    "            df_parents_all.loc[ind, \"end_frame\"] = int(e_frame)\n",
    "            curr_id = curr_col[-1]#change0816#change0921\n",
    "            df_parents_all.loc[ind, \"child_id\"] = curr_id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            frames_traject_same_label[row:e_frame + 1, col] = curr_id\n",
    "\n",
    "        assert not(df_parents_all.isnull().values.any()), \"Problem! dataframe contains NaN values\"\n",
    "        df_parents_all = self.clean_repetition(df_parents_all.astype(int))\n",
    "        return df_parents_all.astype(int), frames_traject_same_label\n",
    "\n",
    "    def df2str(self, df_track):\n",
    "        \"\"\"\n",
    "        L B E P where\n",
    "        L - a unique label of the track (label of markers, 16-bit positive value)\n",
    "        B - a zero-based temporal index of the frame in which the track begins\n",
    "        E - a zero-based temporal index of the frame in which the track ends\n",
    "        P - label of the parent track (0 is used when no parent is defined)\n",
    "        \"\"\"\n",
    "        str_track = ''\n",
    "        for i in df_track.index:\n",
    "            L = df_track.loc[i, \"child_id\"]\n",
    "            B = df_track.loc[i, \"start_frame\"]\n",
    "            E = df_track.loc[i, \"end_frame\"]\n",
    "            P = df_track.loc[i, \"parent_id\"]\n",
    "            str_track += f\"{L} {B} {E} {P}\\n\"\n",
    "\n",
    "        return str_track\n",
    "\n",
    "    def merge_edges(self):\n",
    "        in_output_pred, out_output_pred = self.match_edges()\n",
    "        if self.merge_operation == 'OR' or self.merge_operation == 'AND':\n",
    "            in_outputs_soft = torch.sigmoid(in_output_pred)\n",
    "            in_outputs_hard = (in_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            out_outputs_soft = torch.sigmoid(out_output_pred)\n",
    "            out_outputs_hard = (out_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            final_outputs_hard = np.bitwise_or(in_outputs_hard,out_outputs_hard) if self.merge_operation == 'OR'\\\n",
    "                else np.bitwise_and(in_outputs_hard,out_outputs_hard)\n",
    "\n",
    "        if self.merge_operation == 'AVG':\n",
    "            avg_outputs_soft = torch.sigmoid(in_output_pred) + torch.sigmoid(out_output_pred)\n",
    "            avg_outputs_soft = avg_outputs_soft / 2.0\n",
    "            final_outputs_hard = (avg_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "        self.outputs_hard = final_outputs_hard\n",
    "        return final_outputs_hard\n",
    "\n",
    "    def megre_match_edges(self, edge_index, output_pred):\n",
    "\n",
    "        assert torch.all(edge_index[:, ::2] == edge_index[[1, 0], 1::2]), \\\n",
    "            \"The results don't match!\"\n",
    "        edge_index = edge_index[:, ::2]\n",
    "        in_output_pred = output_pred[::2]\n",
    "        out_output_pred = output_pred[1::2]\n",
    "\n",
    "        if self.merge_operation == 'OR' or self.merge_operation == 'AND':\n",
    "            in_outputs_soft = torch.sigmoid(in_output_pred)\n",
    "            in_outputs_hard = (in_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            out_outputs_soft = torch.sigmoid(out_output_pred)\n",
    "            out_outputs_hard = (out_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "            final_outputs_hard = np.bitwise_or(in_outputs_hard, out_outputs_hard) if self.merge_operation == 'OR' \\\n",
    "                else np.bitwise_and(in_outputs_hard, out_outputs_hard)\n",
    "\n",
    "        elif self.merge_operation == 'AVG':\n",
    "            avg_outputs_soft = torch.sigmoid(in_output_pred) + torch.sigmoid(out_output_pred)\n",
    "            avg_outputs_soft = avg_outputs_soft / 2.0\n",
    "            final_outputs_hard = (avg_outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "        return final_outputs_hard, edge_index\n",
    "\n",
    "    def find_connected_edges(self):\n",
    "        edge_index, df, outputs = self.edge_index, self.df_preds, self.output_pred\n",
    "\n",
    "        if not self.directed:\n",
    "            final_outputs_hard, edge_index = self.megre_match_edges(edge_index.detach().clone(), outputs.detach().clone())\n",
    "            self.outputs_hard = final_outputs_hard\n",
    "            self.edge_index = edge_index\n",
    "        else:\n",
    "            outputs_soft = torch.sigmoid(outputs)\n",
    "            self.outputs_hard = (outputs_soft > self.decision_threshold).int()\n",
    "\n",
    "    def create_trajectory(self):\n",
    "        edge_index, df, outputs_hard = self.edge_index, self.df_preds, self.outputs_hard\n",
    "        self.flag_id0_terminate = False\n",
    "        # extract values from arguments\n",
    "        connected_indices = edge_index[:, outputs_hard.bool()]\n",
    "\n",
    "        # find number of frames for iterations\n",
    "        frame_nums = np.unique(df.frame_num)\n",
    "        # find number of cells in each frame and build matrix [num_frames, max_cells]\n",
    "        max_elements = [df.frame_num.isin([i]).sum() for i in frame_nums]\n",
    "        all_frames_traject = np.zeros((frame_nums.shape[0], max(max_elements)))\n",
    "\n",
    "        # intialize the matrix with -2 meaning empty cell, -1 means end of trajectory,\n",
    "        # other value means the number of node in the graph\n",
    "        all_frames_traject[:, :] = -2\n",
    "        all_trajectory_dict = {}\n",
    "        str_track = ''\n",
    "        df_parents = []\n",
    "        for frame_ind in frame_nums:\n",
    "            mask_frame_ind = df.frame_num.isin([frame_ind])  # find the places containing frame_ind\n",
    "\n",
    "            # filter the places with the specific frame_ind and take the corresponding indices\n",
    "            nodes = df.loc[mask_frame_ind, :]\n",
    "            nodes_indices = nodes.index.values\n",
    "\n",
    "            next_frame_indices = np.array([])\n",
    "\n",
    "            if frame_ind == 0:  # for the first frame, we should fill the first row with node indices\n",
    "                all_frames_traject[frame_ind, :nodes_indices.shape[0]] = nodes_indices\n",
    "                df_parents.append(self.fill_first_frame(nodes_indices))\n",
    "\n",
    "            num_starts = 0\n",
    "            cell_starts = []\n",
    "            for i in nodes_indices:\n",
    "                if i in connected_indices[0, :]:\n",
    "                    ind_place = np.argwhere(connected_indices[0, :] == i)\n",
    "\n",
    "                    if ind_place.shape[-1] > 1:\n",
    "                        next_frame_ind = connected_indices[1, ind_place].numpy().squeeze()\n",
    "                        if self.is_3d:\n",
    "                            next_frame = df.loc[next_frame_ind, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "                            curr_node = df.loc[i, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "                        else:\n",
    "                            next_frame = df.loc[next_frame_ind, [\"centroid_row\", \"centroid_col\"]].values\n",
    "                            curr_node = df.loc[i, [\"centroid_row\", \"centroid_col\"]].values\n",
    "\n",
    "                        distance = ((next_frame - curr_node) ** 2).sum(axis=-1)\n",
    "                        nearest_cell = np.argmin(distance, axis=-1)\n",
    "                        # add to the array\n",
    "                        next_node_ind = next_frame_ind[nearest_cell]\n",
    "\n",
    "                    elif ind_place.shape[-1] == 1:  # one node in the next frame is connected to current node\n",
    "                        next_node_ind = connected_indices[1, ind_place[0]]\n",
    "                    else:  # no node in the next frame is connected to current node -\n",
    "                        # in this case we end the trajectory\n",
    "                        next_node_ind = -1\n",
    "\n",
    "                else:\n",
    "                    # we dont find the current node in the edge indices matrix - meaning we dont have a connection\n",
    "                    # for the node - in this case we end the trajectory and the cell\n",
    "                    if i == 0:\n",
    "                        self.flag_id0_terminate = True\n",
    "                    next_node_ind = -1\n",
    "\n",
    "                next_frame_indices = np.append(next_frame_indices, next_node_ind)\n",
    "                # count the number of starting trajectories\n",
    "                start, all_frames_traject = self.insert_in_specific_col(all_frames_traject, frame_ind, i, next_node_ind)\n",
    "                num_starts += start\n",
    "\n",
    "                if start == 1:  # append the id of the cell to the list\n",
    "                    cell_starts.append(i)\n",
    "\n",
    "            if num_starts > 0:\n",
    "                df_parents.append(self.find_parent_cell(frame_ind, all_frames_traject, df, num_starts, cell_starts))\n",
    "            all_trajectory_dict[frame_ind] = {'from': nodes_indices, 'to': next_frame_indices}\n",
    "\n",
    "        all_frames_traject = all_frames_traject.astype(int)\n",
    "\n",
    "        # create csv contains all the relevant information for the res_track.txt\n",
    "        df_parents_all = pd.concat(df_parents, axis=0).reset_index(drop=True)\n",
    "        df_track_res, trajectory_same_label = self.set_all_info(df_parents_all, all_frames_traject)\n",
    "\n",
    "        # convert csv to res_track.txt and res_track_real.txt\n",
    "        str_track = self.df2str(df_track_res)\n",
    "\n",
    "        # convert all_frames_traject to csv\n",
    "        df_trajectory = pd.DataFrame(all_frames_traject)\n",
    "\n",
    "\n",
    "        self.all_frames_traject = all_frames_traject\n",
    "        self.trajectory_same_label = trajectory_same_label\n",
    "        self.df_trajectory = df_trajectory\n",
    "        self.df_track = df_track_res\n",
    "        self.file_str = str_track\n",
    "\n",
    "        return all_frames_traject, trajectory_same_label, \\\n",
    "               df_trajectory,  \\\n",
    "               str_track\n",
    "\n",
    "    def get_pred(self, idx):\n",
    "        pred = None\n",
    "        if len(self.results):\n",
    "            im_path = self.results[idx]\n",
    "            pred = io.imread(im_path)\n",
    "            if self.is_3d and len(pred.shape) != 3:\n",
    "                pred = np.stack(imageio.mimread(im_path))\n",
    "                assert len(pred.shape) == 3, f\"Expected 3d dimiension! but {pred.shape}\"\n",
    "        return pred\n",
    "\n",
    "    def create_save_dir(self):\n",
    "        num_seq = self.dir_result.split('/')[-1][:2]\n",
    "        save_tra_dir = osp.join(self.dir_result, f\"../{num_seq}_RES\")\n",
    "        self.save_tra_dir =save_tra_dir\n",
    "        os.makedirs(self.save_tra_dir, exist_ok=True)\n",
    "\n",
    "    def save_new_pred(self, new_pred, idx):\n",
    "        idx_str = \"%03d\" % idx\n",
    "        file_name = f\"mask{idx_str}.tif\"\n",
    "        full_dir = osp.join(self.save_tra_dir, file_name)\n",
    "        io.imsave(full_dir, new_pred.astype(np.uint32))\n",
    "\n",
    "    def check_ids_consistent(self, frame_ind, pred_ids, curr_ids):\n",
    "\n",
    "        # predID_not_in_currID = [x for x in pred_ids if x not in curr_ids]\n",
    "        # currID_not_in_predID = [x for x in curr_ids if x not in pred_ids]\n",
    "        # flag1 = len(predID_not_in_currID) == 1 and predID_not_in_currID[0] == 0\n",
    "        # flag2 = len(currID_not_in_predID) == 0\n",
    "        # if not flag1:\n",
    "        #     str_print = f\"Frame {frame_ind}: Find segmented cell {predID_not_in_currID} without assigned labels\"\n",
    "        #     warnings.warn(str_print)\n",
    "        \n",
    "        #change0816\n",
    "        # if not flag2:\n",
    "            # print('pred_ids', pred_ids)\n",
    "            # print('curr_ids:', curr_ids)\n",
    "            # print('currID_not_in_predID', currID_not_in_predID)\n",
    "\n",
    "        flag1 = 1\n",
    "        flag2 = 1\n",
    "        predID_not_in_currID = 0\n",
    "\n",
    "        # assert flag2, f\"Frame {frame_ind}: Find assigned labels {currID_not_in_predID} \" \\\n",
    "        #               f\"which are not appears in the final saved results\"\n",
    "\n",
    "        return flag1, predID_not_in_currID\n",
    "    \n",
    "\n",
    "    def fix_inconsistent(self, pred_prob_ids, pred):\n",
    "        for id in pred_prob_ids:\n",
    "            if id == 0:\n",
    "                continue\n",
    "            pred[pred == id] = 0\n",
    "        return pred\n",
    "\n",
    "    def fill_mask_labels(self, debug=False):\n",
    "        self.create_save_dir()\n",
    "        all_frames_traject, trajectory_same_label = self.all_frames_traject, self.trajectory_same_label\n",
    "        df = self.df_preds\n",
    "        n_rows, n_cols = all_frames_traject.shape\n",
    "        #change0816\n",
    "        self.flag_id0_terminate = True\n",
    "\n",
    "\n",
    "        count_diff_vals = 0\n",
    "        for idx in range(n_rows):\n",
    "            pred = self.get_pred(idx)\n",
    "            pred_copy = pred.copy()\n",
    "            pred_copy_32 = pred_copy.astype('uint32')\n",
    "            curr_row = all_frames_traject[idx, :]\n",
    "            mask_id = np.bitwise_and(curr_row != -1, curr_row != -2)\n",
    "            graph_ids = curr_row[mask_id]\n",
    "            graph_true_ids = trajectory_same_label[idx, mask_id]\n",
    "            mask_where = np.ones_like(pred)\n",
    "            frame_ids = []\n",
    "            for id, true_id in zip(graph_ids, graph_true_ids):\n",
    "                flag_id0 = true_id == 0\n",
    "                if flag_id0:    # edge case when the cell with id=0 terminate after one frame\n",
    "                    if self.flag_id0_terminate:\n",
    "                        new_id = trajectory_same_label.max() + 1\n",
    "                        self.df_track.child_id[self.df_track.child_id == 0] = new_id\n",
    "                        self.file_str = self.df2str(self.df_track)\n",
    "                    else:\n",
    "                        assert False, \"Problem!\"\n",
    "                if self.is_3d:\n",
    "                    cell_center = df.loc[id, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values.astype(int)\n",
    "                    depth_center, row_center, col_center = cell_center[0], cell_center[1], cell_center[2]\n",
    "                    if self.center_coord:\n",
    "                        n_depth_img, n_row_img, n_col_img = pred.shape\n",
    "                        depth_center += n_depth_img // 2\n",
    "                        row_center += n_row_img // 2\n",
    "                        col_center += n_col_img // 2\n",
    "\n",
    "                    val = pred[depth_center, row_center, col_center]\n",
    "                    if 'seg_label' in df.columns:\n",
    "                        v_old = val\n",
    "                        val = df.loc[id, \"seg_label\"]\n",
    "                        count_diff_vals += 1 if v_old != val else 0\n",
    "\n",
    "                    if val == 0:\n",
    "                        if np.any(pred[depth_center-3:depth_center+3, row_center-3:row_center+3, col_center-3:col_center+3] != 0):\n",
    "                            area = pred[depth_center-3:depth_center+3, row_center-3:row_center+3, col_center-3:col_center+3]\n",
    "                            unique_labels, counts = np.unique(area, return_counts=True)\n",
    "                            mask = unique_labels != 0\n",
    "                            unique_labels = unique_labels[mask]\n",
    "                            counts = counts[mask]\n",
    "                            val = unique_labels[np.argmax(counts)]\n",
    "                        else:\n",
    "                            print(\"Problem! The provided center coordinates value is zero, should be labeled with other value\")\n",
    "                            print(df.loc[id, [\"seg_label\", \"frame_num\",  \"centroid_depth\", \"centroid_row\", \"centroid_col\", \"min_depth_bb\",\n",
    "                                              \"min_row_bb\", \"min_col_bb\", \"max_depth_bb\", \"max_row_bb\", \"max_col_bb\"]].astype(int))\n",
    "                            print()\n",
    "                            continue\n",
    "                else:\n",
    "                    cell_center = df.loc[id, [\"centroid_row\", \"centroid_col\"]].values.astype(int)\n",
    "                    row_center, col_center = cell_center[0], cell_center[1]\n",
    "                    if self.center_coord:\n",
    "                        n_row_img, n_col_img = pred.shape\n",
    "                        row_center += n_row_img // 2\n",
    "                        col_center += n_col_img // 2\n",
    "\n",
    "                    val = pred[row_center, col_center]\n",
    "                    if 'seg_label' in df.columns:\n",
    "                        v_old = val\n",
    "                        val = df.loc[id, \"seg_label\"]\n",
    "                        count_diff_vals += 1 if v_old != val else 0\n",
    "\n",
    "                    if val == 0:\n",
    "                        if np.any(pred[row_center-3:row_center+3, col_center-3:col_center+3] != 0):\n",
    "                            area = pred[row_center-3:row_center+3, col_center-3:col_center+3]\n",
    "                            unique_labels, counts = np.unique(area, return_counts=True)\n",
    "                            mask = unique_labels != 0\n",
    "                            unique_labels = unique_labels[mask]\n",
    "                            counts = counts[mask]\n",
    "                            val = unique_labels[np.argmax(counts)]\n",
    "                        else:\n",
    "                            print(\n",
    "                                \"Problem! The provided center coordinates value is zero, should be labeled with other value\")\n",
    "                            print(df.loc[id, [\"seg_label\", \"frame_num\", \"centroid_row\", \"centroid_col\",\n",
    "                                              \"min_row_bb\", \"min_col_bb\", \"max_row_bb\", \"max_col_bb\"]].astype(int))\n",
    "                            print()\n",
    "                            continue\n",
    "\n",
    "                assert val != 0, \"Problem! The provided center coordinates value is zero, \" \\\n",
    "                                 \"should be labeled with other value\"\n",
    "                if flag_id0:\n",
    "                    true_id = new_id\n",
    "                mask_val = (pred_copy_32 == val).copy()\n",
    "                mask_curr = np.logical_and(mask_val, mask_where)\n",
    "                pred_copy_32[mask_curr] = true_id\n",
    "                mask_where = np.logical_and(np.logical_not(mask_val), mask_where)\n",
    "\n",
    "                frame_ids.append(true_id)\n",
    "\n",
    "            isOK, predID_not_in_currID = self.check_ids_consistent(idx, np.unique(pred_copy_32), frame_ids)\n",
    "            if not debug:\n",
    "                if not isOK:\n",
    "                    pred_copy_32 = self.fix_inconsistent(predID_not_in_currID, pred_copy_32)\n",
    "                self.save_new_pred(pred_copy_32, idx)\n",
    "        print(f\"Number of different vals: {count_diff_vals}\")\n",
    "        self.save_txt(self.file_str, self.save_tra_dir, 'res_track.txt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /data/sunrui/celldata/20231018-SOX2-CELLID-A/1SOX2-CELLID-A//01_RES_inference/pytorch_geometric_data.pt\n",
      "Load /data/sunrui/celldata/20231018-SOX2-CELLID-A/1SOX2-CELLID-A//01_RES_inference/all_data_df.csv\n",
      "Load /data/sunrui/celldata/20231018-SOX2-CELLID-A/1SOX2-CELLID-A//01_RES_inference/raw_output.pt\n",
      "tensor([0, 1, 0,  ..., 0, 0, 0], dtype=torch.int32)\n",
      "torch.Size([2, 107721])\n",
      "torch.Size([107721])\n",
      "tensor([[     0,      2,      3,  ..., 113012, 113013, 113014],\n",
      "        [   311,    323,    318,  ..., 113371, 113379, 113367]])\n",
      "torch.Size([2, 107721])\n",
      "Connected Indices (After Filtering):\n",
      "tensor([[     0,      2,      3,  ..., 113012, 113013, 113014],\n",
      "        [   311,    323,    318,  ..., 113371, 113379, 113367]])\n",
      "torch.Size([2, 99642])\n",
      "tensor([15.2585, 11.2731, 15.4440,  ...,  8.3572, 14.5784,  6.8848])\n",
      "torch.Size([99642])\n",
      "Number of different vals: 1\n"
     ]
    }
   ],
   "source": [
    "root_path = r'/data/sunrui/celldata/20231018-SOX2-CELLID-A/1SOX2-CELLID-A/'\n",
    "modality = '2D'\n",
    "path_inference_output = root_path +'/01_RES_inference'\n",
    "path_Seg_result = root_path + '/01_GT/SEG/'\n",
    "is_3d = '3d' in modality.lower() \n",
    "directed = True\n",
    "merge_operation = 'AND'\n",
    "pp = Postprocess(is_3d=is_3d,\n",
    "                    type_masks='tif', merge_operation=merge_operation,\n",
    "                    decision_threshold=0.5,\n",
    "                    path_inference_output=path_inference_output, center_coord=False,\n",
    "                    directed=directed,\n",
    "                    path_seg_result=path_Seg_result)\n",
    "all_frames_traject, trajectory_same_label, df_trajectory, str_track = pp.create_trajectory()\n",
    "pp.fill_mask_labels(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajectory_same_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajectory_same_label\n",
    "# df_same_tra = pd.DataFrame(trajectory_same_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_same_tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# if __name__== \"__main__\":\n",
    "#     import argparse\n",
    "\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('-modality', type=str, required=True, help='2D/3D modality')\n",
    "#     parser.add_argument('-iseg', type=str, required=True, help='segmentation output directory')\n",
    "#     parser.add_argument('-oi', type=str, required=True, help='inference output directory')\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     modality = args.modality\n",
    "#     assert modality == '2D' or modality == '3D'\n",
    "\n",
    "#     path_inference_output = args.oi\n",
    "#     path_Seg_result = args.iseg\n",
    "\n",
    "#     is_3d = '3d' in modality.lower()\n",
    "#     directed = True\n",
    "#     merge_operation = 'AND'\n",
    "\n",
    "#     pp = Postprocess(is_3d=is_3d,\n",
    "#                      type_masks='tif', merge_operation=merge_operation,\n",
    "#                      decision_threshold=0.5,\n",
    "#                      path_inference_output=path_inference_output, center_coord=False,\n",
    "#                      directed=directed,\n",
    "#                      path_seg_result=path_Seg_result)\n",
    "#     all_frames_traject, trajectory_same_label, df_trajectory, str_track = pp.create_trajectory()\n",
    "#     pp.fill_mask_labels(debug=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell-tracking-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
