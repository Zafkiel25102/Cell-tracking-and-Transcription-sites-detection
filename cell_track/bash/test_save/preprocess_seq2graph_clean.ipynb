{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3,6'\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage.measure import regionprops\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "import sys\n",
    "# cur_dir = os.path.split(os.path.abspath(__file__))[0]\n",
    "# con_pth = cur_dir.rsplit('/',2)[0]\n",
    "# sys.path.append(con_pth)\n",
    "from src_metric_learning.modules.resnet_2d.resnet import set_model_architecture, MLP\n",
    "from skimage.morphology import label\n",
    "\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    \"\"\"Example dataset class for loading images from folder.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 path: str,\n",
    "                 path_result: str,\n",
    "\n",
    "                 type_img: str,\n",
    "                 type_masks: str\n",
    "                 ):\n",
    "\n",
    "        self.path = path\n",
    "\n",
    "        self.path_result = path_result\n",
    "\n",
    "        dir_img = path\n",
    "        dir_results = path_result\n",
    "\n",
    "        self.images = []\n",
    "        if os.path.exists(dir_img):\n",
    "            self.images = [os.path.join(dir_img, fname) for fname in sorted(os.listdir(dir_img))\n",
    "                           if type_img in fname]\n",
    "\n",
    "        self.results = []\n",
    "        if os.path.exists(dir_results):\n",
    "            self.results = [os.path.join(dir_results, fname) for fname in sorted(os.listdir(dir_results))\n",
    "                            if type_masks in fname]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert len(self.images) or len(self.images), \"both directories are empty, please fix it!\"\n",
    "\n",
    "        im_path, image = None, None\n",
    "        if len(self.images):\n",
    "            im_path = self.images[idx]\n",
    "            image = np.array(Image.open(im_path))\n",
    "\n",
    "        result_path, result = None, None\n",
    "        if len(self.results):\n",
    "            result_path = self.results[idx]\n",
    "            result = np.array(Image.open(result_path))\n",
    "        flag = True\n",
    "        if im_path is not None:\n",
    "            flag = False\n",
    "            im_num = im_path.split(\".\")[-2][-3:]\n",
    "\n",
    "        if result_path is not None:\n",
    "            flag = False\n",
    "            result_num = result_path.split(\".\")[-2][-3:]\n",
    "\n",
    "        if flag:\n",
    "            assert im_num == result_num, f\"Image number ({im_num}) is not equal to result number ({result_num})\"\n",
    "\n",
    "        return image, result, im_path, result_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def padding(self, img):\n",
    "        if self.flag_new_roi:\n",
    "            desired_size_row = self.global_delta_row\n",
    "            desired_size_col = self.global_delta_col\n",
    "        else:\n",
    "            desired_size_row = self.roi_model['row']\n",
    "            desired_size_col = self.roi_model['col']\n",
    "        delta_row = desired_size_row - img.shape[0]\n",
    "        delta_col = desired_size_col - img.shape[1]\n",
    "        pad_top = delta_row // 2\n",
    "        pad_left = delta_col // 2\n",
    "\n",
    "        image = cv2.copyMakeBorder(img, pad_top, delta_row - pad_top, pad_left, delta_col - pad_left,\n",
    "                                   cv2.BORDER_CONSTANT, value=self.pad_value)\n",
    "\n",
    "        if self.flag_new_roi:\n",
    "            image = cv2.resize(image, dsize=(self.roi_model['col'], self.roi_model['row']))\n",
    "\n",
    "        return image\n",
    "\n",
    "    def extract_freature_metric_learning(self, bbox, img, seg_mask, ind, normalize_type='MinMaxCell'):\n",
    "        min_row_bb, min_col_bb, max_row_bb, max_col_bb = bbox\n",
    "        img_patch = img[min_row_bb:max_row_bb, min_col_bb:max_col_bb]\n",
    "        msk_patch = seg_mask[min_row_bb:max_row_bb, min_col_bb:max_col_bb] != ind\n",
    "        img_patch[msk_patch] = self.pad_value\n",
    "        img_patch = img_patch.astype(np.float32)\n",
    "\n",
    "        if normalize_type == 'regular':\n",
    "            img = self.padding(img_patch) / self.max_img\n",
    "        elif normalize_type == 'MinMaxCell':\n",
    "            not_msk_patch = np.logical_not(msk_patch)\n",
    "            img_patch[not_msk_patch] = (img_patch[not_msk_patch] - self.min_cell) / (self.max_cell - self.min_cell)\n",
    "            img = self.padding(img_patch)\n",
    "        else:\n",
    "            assert False, \"Not supported this type of normalization\"\n",
    "\n",
    "        img = torch.from_numpy(img).float()\n",
    "        with torch.no_grad():\n",
    "            embedded_img = self.embedder(self.trunk(img[None, None, ...]))\n",
    "\n",
    "        return embedded_img.numpy().squeeze()\n",
    "\n",
    "    def correct_masks(self, min_cell_size):\n",
    "        n_changes = 0\n",
    "        for ind_data in range(self.__len__()):\n",
    "            per_cell_change = False\n",
    "            per_mask_change = False\n",
    "\n",
    "            img, result, im_path, result_path = self[ind_data]\n",
    "            res_save = result.copy()\n",
    "            labels_mask = result.copy()\n",
    "            while True:\n",
    "                bin_mask = labels_mask > 0\n",
    "                re_label_mask = label(bin_mask)\n",
    "                un_labels, counts = np.unique(re_label_mask, return_counts=True)\n",
    "\n",
    "                if np.any(counts < min_cell_size):\n",
    "                    per_mask_change = True\n",
    "\n",
    "                    first_label_ind = np.argwhere(counts < min_cell_size)\n",
    "                    if first_label_ind.size > 1:\n",
    "                        first_label_ind = first_label_ind.squeeze()[0]\n",
    "                    first_label_num = un_labels[first_label_ind]\n",
    "                    labels_mask[re_label_mask == first_label_num] = 0\n",
    "                else:\n",
    "                    break\n",
    "            bin_mask = (labels_mask > 0) * 1.0\n",
    "            result = np.multiply(result, bin_mask)\n",
    "            if not np.all(np.unique(result) == np.unique(res_save)):\n",
    "                warnings.warn(\n",
    "                    f\"pay attention! the labels have changed from {np.unique(res_save)} to {np.unique(result)}\")\n",
    "\n",
    "\n",
    "            for ind, id_res in enumerate(np.unique(result)):\n",
    "                if id_res == 0:\n",
    "                    continue\n",
    "                bin_mask = (result == id_res).copy()\n",
    "                while True:\n",
    "                    re_label_mask = label(bin_mask)\n",
    "                    un_labels, counts = np.unique(re_label_mask, return_counts=True)\n",
    "\n",
    "                    if np.any(counts < min_cell_size):\n",
    "                        per_cell_change = True\n",
    "\n",
    "                        first_label_ind = np.argwhere(counts < min_cell_size)\n",
    "                        if first_label_ind.size > 1:\n",
    "                            first_label_ind = first_label_ind.squeeze()[0]\n",
    "                        first_label_num = un_labels[first_label_ind]\n",
    "                        curr_mask = np.logical_and(result == id_res, re_label_mask == first_label_num)\n",
    "                        bin_mask[curr_mask] = False\n",
    "                        result[curr_mask] = 0.0\n",
    "                    else:\n",
    "                        break\n",
    "                while True:\n",
    "                    re_label_mask = label(bin_mask)\n",
    "                    un_labels, counts = np.unique(re_label_mask, return_counts=True)\n",
    "                    if un_labels.shape[0] > 2:\n",
    "                        per_cell_change = True\n",
    "                        n_changes += 1\n",
    "                        first_label_ind = np.argmin(counts)\n",
    "                        if first_label_ind.size > 1:\n",
    "                            first_label_ind = first_label_ind.squeeze()[0]\n",
    "                        first_label_num = un_labels[first_label_ind]\n",
    "                        curr_mask = np.logical_and(result == id_res, re_label_mask == first_label_num)\n",
    "                        bin_mask[curr_mask] = False\n",
    "                        result[curr_mask] = 0.0\n",
    "                    else:\n",
    "                        break\n",
    "            if not np.all(np.unique(result) == np.unique(res_save)):\n",
    "                warnings.warn(\n",
    "                    f\"pay attention! the labels have changed from {np.unique(res_save)} to {np.unique(result)}\")\n",
    "            if per_cell_change or per_mask_change:\n",
    "                n_changes += 1\n",
    "                res1 = (res_save > 0) * 1.0\n",
    "                res2 = (result > 0) * 1.0\n",
    "                n_pixels = np.abs(res1 - res2).sum()\n",
    "                print(f\"per_mask_change={per_mask_change}, per_cell_change={per_cell_change}, number of changed pixels: {n_pixels}\")\n",
    "                io.imsave(result_path, result.astype(np.uint16), compression='')\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"number of detected changes: {n_changes}\")\n",
    "\n",
    "\n",
    "    def find_min_max_and_roi(self):\n",
    "        global_min = 2 ** 16 - 1\n",
    "        global_max = 0\n",
    "        global_delta_row = 0\n",
    "        global_delta_col = 0\n",
    "        counter = 0\n",
    "        for ind_data in range(self.__len__()):\n",
    "            img, result, im_path, result_path = self[ind_data]\n",
    "\n",
    "            for ind, id_res in enumerate(np.unique(result)):\n",
    "                if id_res == 0:\n",
    "                    continue\n",
    "\n",
    "                properties = regionprops(np.uint8(result == id_res), img)[0]\n",
    "                min_row_bb, min_col_bb, max_row_bb, max_col_bb = properties.bbox\n",
    "                delta_row = np.abs(max_row_bb - min_row_bb)\n",
    "                delta_col = np.abs(max_col_bb - min_col_bb)\n",
    "\n",
    "                if (delta_row > self.roi_model['row']) or (delta_col > self.roi_model['col']):\n",
    "                    counter += 1\n",
    "\n",
    "                global_delta_row = max(global_delta_row, delta_row)\n",
    "                global_delta_col = max(global_delta_col, delta_col)\n",
    "\n",
    "            res_bin = result != 0\n",
    "            # min_curr = img[res_bin].min()\n",
    "            # max_curr = img[res_bin].max()\n",
    "            try:\n",
    "                # 执行操作\n",
    "                min_curr = img[res_bin].min()\n",
    "                max_curr = img[res_bin].max()\n",
    "            except ValueError as e:\n",
    "                # 处理空图像的情况\n",
    "                print(\"Empty image detected. Error:\", e)\n",
    "                continue  # 跳过当前图像\n",
    "\n",
    "\n",
    "            global_min = min(global_min, min_curr)\n",
    "            global_max = max(global_max, max_curr)\n",
    "        print(counter)\n",
    "        print(f\"global_delta_row: {global_delta_row}\")\n",
    "        print(f\"global_delta_col: {global_delta_col}\")\n",
    "        #修改\n",
    "        print('result_shape:',result.shape)\n",
    "        print('img_shape:', img.shape)\n",
    "        self.min_cell = global_min\n",
    "        self.max_cell = global_max\n",
    "\n",
    "        self.global_delta_row = global_delta_row\n",
    "        self.global_delta_col = global_delta_col\n",
    "\n",
    "    def preprocess_features_loop_by_results_w_metric_learning(self, path_to_write, dict_path):\n",
    "        dict_params = torch.load(dict_path)\n",
    "\n",
    "        self.roi_model = dict_params['roi']\n",
    "        self.find_min_max_and_roi()\n",
    "        self.flag_new_roi = self.global_delta_row > self.roi_model['row'] or self.global_delta_col > self.roi_model['col']\n",
    "        if self.flag_new_roi:\n",
    "            self.global_delta_row = max(self.global_delta_row, self.roi_model['row'])\n",
    "            self.global_delta_col = max(self.global_delta_col, self.roi_model['col'])\n",
    "            print(\"Assign new region of interest\")\n",
    "            print(f\"old ROI: {self.roi_model}, new: row: {self.global_delta_row}, col : {self.global_delta_col}\")\n",
    "        else:\n",
    "            print(\"We don't assign new region of interest - use the old one\")\n",
    "\n",
    "        self.pad_value = dict_params['pad_value']\n",
    "        # models params\n",
    "        model_name = dict_params['model_name']\n",
    "        mlp_dims = dict_params['mlp_dims']\n",
    "        mlp_normalized_features = dict_params['mlp_normalized_features']\n",
    "        # models state_dict\n",
    "        trunk_state_dict = dict_params['trunk_state_dict']\n",
    "        embedder_state_dict = dict_params['embedder_state_dict']\n",
    "\n",
    "        trunk = set_model_architecture(model_name)\n",
    "        trunk.load_state_dict(trunk_state_dict)\n",
    "        self.trunk = trunk\n",
    "        self.trunk.eval()\n",
    "\n",
    "        embedder = MLP(mlp_dims, normalized_feat=mlp_normalized_features)\n",
    "        embedder.load_state_dict(embedder_state_dict)\n",
    "        self.embedder = embedder\n",
    "        self.embedder.eval()\n",
    "\n",
    "        cols = [\"seg_label\",\n",
    "                \"frame_num\",\n",
    "                \"area\",\n",
    "                \"min_row_bb\", \"min_col_bb\", \"max_row_bb\", \"max_col_bb\",\n",
    "                \"centroid_row\", \"centroid_col\",\n",
    "                \"major_axis_length\", \"minor_axis_length\",\n",
    "                \"max_intensity\", \"mean_intensity\", \"min_intensity\"\n",
    "                ]\n",
    "\n",
    "\n",
    "        cols_resnet = [f'feat_{i}' for i in range(mlp_dims[-1])]\n",
    "        cols += cols_resnet\n",
    "\n",
    "        for ind_data in range(self.__len__()):\n",
    "            img, result, im_path, result_path = self[ind_data]\n",
    "            #修改\n",
    "            # print('result_shape:',result.shape)\n",
    "            # print('img_shape:', img.shape)\n",
    "\n",
    "            im_num = im_path.split(\".\")[-2][-3:]\n",
    "            result_num = result_path.split(\".\")[-2][-3:]\n",
    "            assert im_num == result_num, f\"Image number ({im_num}) is not equal to result number ({result_num})\"\n",
    "\n",
    "            num_labels = np.unique(result).shape[0] - 1\n",
    "\n",
    "            df = pd.DataFrame(index=range(num_labels), columns=cols)\n",
    "\n",
    "            for ind, id_res in enumerate(np.unique(result)):\n",
    "                # Color 0 is assumed to be background or artifacts\n",
    "                row_ind = ind - 1\n",
    "                if id_res == 0:\n",
    "                    continue\n",
    "\n",
    "                # extracting statistics using regionprops\n",
    "                properties = regionprops(np.uint8(result == id_res), img)[0]\n",
    "\n",
    "                embedded_feat = self.extract_freature_metric_learning(properties.bbox, img.copy(), result.copy(), id_res)\n",
    "                df.loc[row_ind, cols_resnet] = embedded_feat\n",
    "                df.loc[row_ind, \"seg_label\"] = id_res\n",
    "\n",
    "                df.loc[row_ind, \"area\"] = properties.area\n",
    "\n",
    "                df.loc[row_ind, \"min_row_bb\"], df.loc[row_ind, \"min_col_bb\"], \\\n",
    "                df.loc[row_ind, \"max_row_bb\"], df.loc[row_ind, \"max_col_bb\"] = properties.bbox\n",
    "\n",
    "                df.loc[row_ind, \"centroid_row\"], df.loc[row_ind, \"centroid_col\"] = \\\n",
    "                    properties.centroid[0].round().astype(np.int16), \\\n",
    "                    properties.centroid[1].round().astype(np.int16)\n",
    "\n",
    "                df.loc[row_ind, \"major_axis_length\"], df.loc[row_ind, \"minor_axis_length\"] = \\\n",
    "                    properties.major_axis_length, properties.minor_axis_length\n",
    "\n",
    "                df.loc[row_ind, \"max_intensity\"], df.loc[row_ind, \"mean_intensity\"], df.loc[row_ind, \"min_intensity\"] = \\\n",
    "                    properties.max_intensity, properties.mean_intensity, properties.min_intensity\n",
    "\n",
    "\n",
    "            df.loc[:, \"frame_num\"] = int(im_num)\n",
    "\n",
    "            if df.isnull().values.any():\n",
    "                warnings.warn(\"Pay Attention! there are Nan values!\")\n",
    "\n",
    "            full_dir = op.join(path_to_write, \"csv\")\n",
    "            os.makedirs(full_dir, exist_ok=True)\n",
    "            file_path = op.join(full_dir, f\"frame_{im_num}.csv\")\n",
    "            df.to_csv(file_path, index=False)\n",
    "        print(f\"files were saved to : {full_dir}\")\n",
    "\n",
    "\n",
    "def create_csv(input_images, input_seg, input_model, output_csv, min_cell_size):\n",
    "    dict_path = input_model\n",
    "    path_output = output_csv\n",
    "    path_Seg_result = input_seg\n",
    "    ds = TestDataset(\n",
    "        path=input_images,\n",
    "        path_result=path_Seg_result,\n",
    "        type_img=\"tif\",\n",
    "        type_masks=\"tif\")\n",
    "    #修改\n",
    "    #ds.correct_masks(min_cell_size)\n",
    "    ds.preprocess_features_loop_by_results_w_metric_learning(path_to_write=path_output,\n",
    "        dict_path=dict_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "global_delta_row: 144\n",
      "global_delta_col: 243\n",
      "result_shape: (1000, 1000)\n",
      "img_shape: (1000, 1000)\n",
      "Assign new region of interest\n",
      "old ROI: {'row': 116, 'col': 119}, new: row: 144, col : 243\n",
      "Using resnet18 model architecture.\n",
      "files were saved to : /data/sunrui/celldata/20230803-2_HBEC_Yoko_Lib5_G+R-_DL/20230803_B11_F0009//01_CSV/csv\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "root_path = r'/data/sunrui/celldata/20230803-2_HBEC_Yoko_Lib5_G+R-_DL/20230803_B11_F0009/'\n",
    "min_cell_size = 20\n",
    "input_images = root_path + r\"/01/\"\n",
    "input_segmentation = root_path + r\"/01_GT/SEG/\"\n",
    "input_model = r\"/home/sunrui/cellwork/track/cell-tracker-gnn-main/outputs/2023-07-06/19-57-00/all_params.pth\"\n",
    "\n",
    "output_csv = root_path + r\"/01_CSV\"\n",
    "\n",
    "create_csv(input_images, input_segmentation, input_model, output_csv, min_cell_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     import argparse\n",
    "\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('-ii', type=str, required=True, help='input images directory')\n",
    "#     parser.add_argument('-iseg', type=str, required=True, help='input segmentation directory')\n",
    "#     parser.add_argument('-im', type=str, required=True, help='metric learning model params directory')\n",
    "#     parser.add_argument('-cs', type=int, required=True, help='min cell size')\n",
    "\n",
    "#     parser.add_argument('-oc', type=str, required=True, help='output csv directory')\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     min_cell_size = args.cs\n",
    "#     input_images = args.ii\n",
    "#     input_segmentation = args.iseg\n",
    "#     input_model = args.im\n",
    "\n",
    "#     output_csv = args.oc\n",
    "\n",
    "#     create_csv(input_images, input_segmentation, input_model, output_csv, min_cell_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell-tracking-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
